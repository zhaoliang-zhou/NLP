{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaOSrvct7dX8"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install ðŸ¤— Transformers and ðŸ¤— Datasets. Uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8GwJkoNj7dYA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5c28db5b-c254-4456-f023-d578207185e1"
   },
   "source": " !pip install transformers datasets evaluate sacrebleu torchtext",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qhd_GW5J7dYB"
   },
   "source": [
    "from tqdm.auto import tqdm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omSuPoLY7dYB"
   },
   "source": [
    "## Q1: Dataset Preparation (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VtQHtK5j7dYB"
   },
   "source": [
    "from datasets import load_dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRQ7Hsrj7dYC"
   },
   "source": [
    "We use the ```load_dataset()``` function to download the dataset. Replace the dummy arguments to download the wmt14 dataset for fr-en translation as provided here: https://huggingface.co/datasets/wmt/wmt14"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "klc-jtLi7dYC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243,
     "referenced_widgets": [
      "8aecab28fc61444887162efdafc24d2b",
      "aab406e81f49463dbeb6f3336c15091a",
      "b85d479090c0445db78fffc344f2b28a",
      "d2275916991343fc9c3487c6f2f42f0b",
      "8d984ce4d92b420fa6e1b82ee01cb84b",
      "d6554cb2c5974c918d03b531f33e9735",
      "045edd3925a3497d8e121c0967ba579d",
      "8bcd9f4e66924eb99cf5c9cf16284e53",
      "3445d42ac5454a0bbd2825f22cf3bf5d",
      "e0291bb3a87d43909b64bb238f184bd1",
      "046061c6a2df41d5985c487bf25ec0e3"
     ]
    },
    "outputId": "c1dbea6f-8039-47d6-a89a-dbb25b1aa53f"
   },
   "source": [
    "dataset = load_dataset(\"wmt14\", \"fr-en\", split='train[:15000]')\n",
    "dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPhRx3w8MrC9",
    "outputId": "79724e59-d2c5-4e75-d67d-09c4f2c0f8d8"
   },
   "cell_type": "code",
   "source": "print(dataset)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OajGgO-R7dYC"
   },
   "source": [
    "Now, we split the dataset into training and testing splits. This is done using the ```train_test_split``` function. Replace the dummy arguments with appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9oCpCOAv7dYC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1d03ba6d-ddc2-4f11-ca2a-aa299e49cc97"
   },
   "source": [
    "split_datasets = dataset.train_test_split(train_size=0.8, seed=2025)\n",
    "split_datasets\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nU3rB0eR7dYD"
   },
   "source": [
    "Define the test dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F0KvRQL07dYD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "57245cf1-7f46-4ed0-a811-11b573ba949d"
   },
   "source": [
    "test_dataset = split_datasets[\"test\"]\n",
    "test_dataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykFRxwh57dYD"
   },
   "source": [
    "Now, follow the same process to split the train dataset to training and validation splits."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kynutdwu7dYD",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "57a710bb31a14ab4a58a425f2db54e07",
      "1ef1960222d248cf8b5e5fd5831494a3",
      "077fbf7a2b1f4dbcbe1d803d7f64e63b",
      "5f6f5ee76013440386dcf349c9456562",
      "c7bb677061484f79ab7ac0403445019e",
      "f54bcd623f1e44eca44cfcdce29e7251",
      "a6d9eabb3ce74904919a44b9d257ac59",
      "79375ca6f18a44c9bc13e25b3cec9c07",
      "3e2a614fc02e4029a38051f7e09854ae",
      "acfaf67f57dc4c90bd0bc5c4a8e9d629",
      "0b36c2cc6ed840c08aa615d2ae496070"
     ]
    },
    "outputId": "718afc6c-aacf-47cd-9d5f-b40eeee2c0ac"
   },
   "source": [
    "# load the validation set\n",
    "split_to_val = load_dataset(\"wmt14\", \"fr-en\", split='validation')\n",
    "# further split the train set into 0.8 train and 0.2 evaluation datasets\n",
    "train_eval_split = split_datasets[\"train\"].train_test_split(train_size=0.8, seed=2025)\n",
    "train_dataset = train_eval_split[\"train\"]\n",
    "eval_dataset = train_eval_split[\"test\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xz4dcIUFMrC-",
    "outputId": "5cc81dc1-ba31-49c4-8c53-56367f135d1c"
   },
   "cell_type": "code",
   "source": [
    "# test code\n",
    "train_eval_split"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2J7AypmH7dYD"
   },
   "source": [
    "## Q2 Prepare for training RNNs (10)\n",
    "In this part, you are required to define the tokenizers for english and french, tokenize the data, and define the dataloaders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaR1qKZs7dYD"
   },
   "source": [
    "Choose and initialize the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qfFHDk3D7dYD"
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased') # CHOOSE AN APPROPRIATE MULTILINGUAL MODEL such as https://huggingface.co/google-bert/bert-base-multilingual-cased"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITKX-cza7dYD"
   },
   "source": [
    "You will need to create a pytorch dataset to process the tokens in the required format. Complete the implementation of the dataset."
   ]
  },
  {
   "metadata": {
    "id": "mmwtmvc3MrC-"
   },
   "cell_type": "code",
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uCKYlKu07dYD"
   },
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataset, input_size, output_size):\n",
    "        source_texts = [text[\"translation\"]['fr'] for text in dataset]\n",
    "        target_texts = [text[\"translation\"]['en'] for text in dataset]\n",
    "        self.source_sentences = tokenizer(source_texts, padding='max_length', truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
    "        self.target_sentences = tokenizer(target_texts, padding='max_length', truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.source_sentences[idx], self.target_sentences[idx]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUl1vQj07dYE"
   },
   "source": [
    "Initialize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u-Hqb62L7dYE"
   },
   "source": [
    "# pick a random vocab size\n",
    "vocab_size = tokenizer.vocab_size\n",
    "train_dataset_rnn = TranslationDataset(train_dataset, vocab_size, vocab_size)\n",
    "eval_dataset_rnn = TranslationDataset(eval_dataset, vocab_size, vocab_size)\n",
    "test_dataset_rnn = TranslationDataset(test_dataset, vocab_size, vocab_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hr4Vv58MMrC-",
    "outputId": "c7f35155-d9b6-42c6-a4b9-682ae3e23151"
   },
   "cell_type": "code",
   "source": [
    "# test code\n",
    "len(test_dataset_rnn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-JfiZAH7dYE"
   },
   "source": [
    "Get the vocab size from the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aR1CEzJN7dYE"
   },
   "source": [
    "vocab_size = tokenizer.vocab_size # This size is used somewhere in the model, think."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8uvrc0R7dYE"
   },
   "source": [
    "Initialize and define the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8W3qVX2N7dYE"
   },
   "source": [
    "#Instantiate the DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "# recommende batch size using powers of 2 - effecient memory usage\n",
    "BATCH_SIZE = 8\n",
    "train_dataloader = DataLoader(train_dataset_rnn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset_rnn, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset_rnn, batch_size=BATCH_SIZE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47aHE1pkMrC_",
    "outputId": "e2893c2b-64ee-4a09-86ea-d32a027cbaa2"
   },
   "cell_type": "code",
   "source": [
    "# test code\n",
    "len(train_dataloader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X03nj-qd7dYE"
   },
   "source": [
    "## Q3: Implementing RNNs (10)\n",
    "Define the RNN model as an encoder-decoder RNN for the task of translation in the cell below. You may refer: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6iYwjZXt7dYE"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kZcyOabn7dYE"
   },
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_p=0.5):\n",
    "        super(Seq2SeqRNN, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size) # embedding layer\n",
    "        self.encoder = nn.RNN(hidden_size, hidden_size, batch_first=True) # encoder\n",
    "        self.dropout = nn.Dropout(p=dropout_p) # drop out layer following tutorial\n",
    "        self.decoder = nn.RNN(hidden_size, hidden_size, batch_first=True) # decoder\n",
    "        self.out = nn.Linear(hidden_size, output_size) #output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        encoder_outputs, hidden = self.encoder(embedded)\n",
    "        decoder_outputs, _ = self.decoder(encoder_outputs, hidden)\n",
    "        output = self.out(decoder_outputs)\n",
    "        return output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SnP9NUtK7dYE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1542aee2-971a-43d1-b97b-2514a0a77a43"
   },
   "source": [
    "input_size = tokenizer.vocab_size\n",
    "output_size = tokenizer.vocab_size\n",
    "model = Seq2SeqRNN(input_size = input_size, hidden_size= 128, output_size = output_size)\n",
    "model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MZb5OZc7dYE"
   },
   "source": [
    "## Q4: Training RNNs (15)\n",
    "In this question, you will define the hyperparameters, loss and optimizer for training. You will then implement a custom training loop."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "INYhxibp7dYE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4a01c45c-0fca-4177-c19f-e448a0596cec"
   },
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7cPIUCd7dYE"
   },
   "source": [
    "define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FeCoP4DC7dYE"
   },
   "source": [
    "#from torch.optim import IMPORT_OPTIMIZER\n",
    "import torch.optim as optim\n",
    "#from torch.nn import IMPORT_LOSS_FUNCTION\n",
    "\n",
    "num_train_epochs = 3 # define epochs for training\n",
    "num_training_steps = num_train_epochs * len(train_dataloader)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)# YOUR LOSS FUNCTION\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) # YOUR OPTIMIZER HERE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2w-eirJ7dYE"
   },
   "source": [
    "Write the training loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "waBwBdVx7dYE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "99f0f290-48ed-4819-f212-47a3c97a6a62"
   },
   "source": [
    "from tqdm import tqdm\n",
    "progress_bar = tqdm(total=num_training_steps, desc=\"Training Progress\")\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_src, batch_tgt in train_dataloader:\n",
    "        ## Complete the training loop\n",
    "        optimizer.zero_grad()\n",
    "        batch_src = batch_src.to(torch.device('cuda'))\n",
    "        batch_tgt = batch_tgt.to(torch.device('cuda'))\n",
    "        output = model(batch_src)\n",
    "        loss = criterion(output.view(-1, output_size), batch_tgt.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation Phase\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    total_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_src, batch_tgt in eval_dataloader:\n",
    "            batch_src = batch_src.to(torch.device('cuda'))\n",
    "            batch_tgt = batch_tgt.to(torch.device('cuda'))\n",
    "            output = model(batch_src)\n",
    "            loss = criterion(output.view(-1, output_size), batch_tgt.view(-1))\n",
    "            total_eval_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "\n",
    "      ### Complete the evaluation phase\n",
    "\n",
    "    avg_loss = total_eval_loss / total_batches if total_batches > 0 else float(\"inf\")\n",
    "    print(f\"Epoch {epoch}: Average Eval Loss: {avg_loss:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-e1x_Lm7dYF"
   },
   "source": [
    "## Q5: Evaluating RNNs for Machine Translation (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrE3V_P17dYF"
   },
   "source": [
    "Implement the calculation of BLEU-1,2,3,4 scores using the ```sacrebleu``` library for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sacrebleu"
   ],
   "metadata": {
    "id": "1l5FBni2l2DT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xddoMFY17dYF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c025c868-6a98-470f-99a2-54d0fe2030b7"
   },
   "source": [
    "model.eval()\n",
    "bleu1, bleu2, bleu3, bleu4 = [],[],[],[]\n",
    "# Complete the testing loop\n",
    "for batch_src, batch_tgt in tqdm(test_dataloader):\n",
    "    batch_src = batch_src.to(torch.device('cuda'))\n",
    "    batch_tgt = batch_tgt.to(torch.device('cuda'))\n",
    "    with torch.no_grad():\n",
    "      output = model(batch_src)\n",
    "    pred_tokens = torch.argmax(output, dim=-1).tolist()\n",
    "    ref_tokens = batch_tgt.tolist()\n",
    "\n",
    "    reference = [[\" \".join(map(str, ref))] for ref in ref_tokens]\n",
    "    hypothese = [\" \".join(map(str, hyp)) for hyp in pred_tokens]\n",
    "\n",
    "    bleu1.append(sacrebleu.corpus_bleu(hypothese, reference).precisions[0]) # BLUE-1 gram\n",
    "    bleu2.append(sacrebleu.corpus_bleu(hypothese, reference).precisions[1]) # BLUE-2 gram\n",
    "    bleu3.append(sacrebleu.corpus_bleu(hypothese, reference).precisions[2]) # BLUE-3 gram\n",
    "    bleu4.append(sacrebleu.corpus_bleu(hypothese, reference).precisions[3]) # BLUE-4 gram\n",
    "\n",
    "print(\"BLEU-1: \", sum(bleu1) / len(bleu1))\n",
    "print(\"BLEU-2: \", sum(bleu2) / len(bleu2))\n",
    "print(\"BLEU-3: \", sum(bleu3) / len(bleu3))\n",
    "print(\"BLEU-4: \", sum(bleu4) / len(bleu4))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "sacrebleu.corpus_bleu(hypothese, reference)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcsdJOGwueV-",
    "outputId": "d2adaf3c-2197-45ce-c45e-593338b4a847"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpaHAQWp7dYF"
   },
   "source": [
    "Congratulations! You can now work with RNNs for the task of Machine Translation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeBy8PO37dYF"
   },
   "source": [
    "## Q6: Prepare for training transformers (10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vauBDs_a7dYJ"
   },
   "source": [
    "In this part we cover the initial setup required before training transformer this including data preprocessing and setting up data collators and loaders.\n",
    "\n",
    "Ensure you have loaded the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AW5Y83Ew7dYK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "95abb71b-b6ed-495c-9be4-ed21ce7b024a"
   },
   "source": "print(dataset)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMGCBjca7dYK"
   },
   "source": [
    "We will begin by tokenizing the data. Based on your model selection load the appropriate tokenizer. We are using models from AutoModelForSeq2SeqLM in this assignment. You can checkout all the available models here: https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qr49H_Bq7dYK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e5b1ef38-cdfe-411b-f5a5-50c2e8856c54"
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"google-t5/t5-base\" #Select a model of your choice: MT5 model\n",
    "#checkpoint ='bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_FwXurd7dYK"
   },
   "source": [
    "We will need to tokenize both our input and outputs. Thus we make use of pre_process() function to generate tokenized model inputs and targets. Ensure you use truncation and padding! The max length will be 128."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KF8_JKSS7dYK"
   },
   "source": [
    "##Implement the preprocess function\n",
    "def preprocess_function(examples):\n",
    "    inputs = [example[\"fr\"] for example in examples[\"translation\"]]\n",
    "    targets = [example[\"en\"] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, padding = \"max_length\", truncation=True, max_length=128, return_tensors=\"pt\") #Instantitate tokenizer to generate model outputs\n",
    "    labels = tokenizer(targets, padding = \"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    # add tokenized target sentence to model inputs\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train_data = train_dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "id": "-IwNWQEf8Fru"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# changed original code to eval_dataset, because val_dataset does not exist\n",
    "tokenized_eval_data = eval_dataset.map(preprocess_function, batched=True)\n"
   ],
   "metadata": {
    "id": "H42Bthkh8GHS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f97ac130c9684c31bbe4736005ce1428",
      "f7da3ede06004d2cb498672266b21410",
      "ea6182b35e584fa197014e74d1726f38",
      "ccdca5d7aafd4b698f632ad8c637c8e4",
      "ad410f7282534d6e8923f4e876834cea",
      "28c43ba6e35240b287f5ddb998f6591a",
      "504ee3f5a3064e58aa8d0efb295033de",
      "c8352910fdb64977b1b9d04ed3561b0a",
      "1193c8fb8ff040cda38d6de45f42632e",
      "e8d880c834e445a5859e5cdecf857b78",
      "6e0379aaed06452796f170e7be63d2ae"
     ]
    },
    "outputId": "a8e75ccc-5217-4893-d47b-d2409ceabe72"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We remove the column 'translation' as we do not require it for training. Also often having columns other than we created using the preprocess_function may lead to errors during training. Since model might get confused which inputs it needs to use."
   ],
   "metadata": {
    "id": "R9KiU8Uw8jpI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train_data = tokenized_train_data.remove_columns(train_dataset.column_names)\n",
    "tokenized_eval_data = tokenized_eval_data.remove_columns(eval_dataset.column_names)"
   ],
   "metadata": {
    "id": "8z_WfysF8Jqz"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train_data.set_format(\"torch\")\n",
    "tokenized_eval_data.set_format(\"torch\")"
   ],
   "metadata": {
    "id": "ES0vpD308KFK"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBKQon-E7dYK"
   },
   "source": [
    "To construct batches of training data for model training, we require collators that set the properties for the batches and data loaders that generate the batches."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8J_Bs4bT7dYK"
   },
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer) #INSTANTIATE THE COLLATOR"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2ErHyp6A7dYK"
   },
   "source": [
    "#Instantiate the DataLoader for training and evaluation data\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_train_data, batch_size=2, shuffle=True)\n",
    "eval_dataloader = DataLoader(tokenized_eval_data, batch_size=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq75QwZr7dYK"
   },
   "source": [
    "## Q7) Choosing & Loading the Model (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1Cr5Z0T7dYK"
   },
   "source": [
    "Choose a pre-trained transformer model that you will use for fine-tuning on the translation dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JZY0-m7L7dYK"
   },
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "checkpoint = \"google-t5/t5-base\" #\n",
    "#checkpoint = 'bert-base-multilingual-cased'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsaL0EAC7dYK"
   },
   "source": [
    "## Q8) Training the Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKlkWxxh7dYK"
   },
   "source": [
    "Now, that we have are data tokenized and ready in batches and model fixed. We will begin with training this model. To do so we must setup the right hyperparameters, then proceed to implment the training loop to train our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e0JWoMi7dYL"
   },
   "source": [
    "For training we require an optimizer and a scheduler to manage the learning rate during the training. Let's set them up before our training loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CxwICUp17dYL"
   },
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 2\n",
    "# for faster training speed pick below number. If time permits, use the number #num_train_epochs * len(train_dataloader)\n",
    "num_training_steps = 2000 #num_train_epochs * len(train_dataloader)\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=0.05)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "output_size = tokenizer.vocab_size\n",
    "output_size"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NC70bmJMlohf",
    "outputId": "ece7a174-f24f-42a3-8128-da79ca14e522"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# debug",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# debug\n",
    "num_training_steps"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snCjMEbweegQ",
    "outputId": "f5d4f385-9a5a-49ce-d3bd-b776b96a38e4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqdgWb_Q7dYL"
   },
   "source": [
    "Finally, we are here!\n",
    "\n",
    "In the loop during training you will run a forward pass, compute the loss, compute the gradients, and then update the weights. (Don't foregt to set gradient to zero!)\n",
    "\n",
    "During the eval phase we simply do a forward pass and compute the loss!"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vg0dH7osqwFw",
    "outputId": "26f6ee21-8b06-4dbb-b1e1-fbd583174cf0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s0iDbp0x7dYL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "b2ec212bb3f34cfd9149d39990f94ea5",
      "edd44d42f249429f8ab5accbe766c4a2",
      "df84be678d6d46fa81abb278ee93892b",
      "09edb0f2dfc44acea70d2a9118970fa5",
      "f2f176bc831a496ab3db566b4453cce6",
      "00d06a6d8f1c4ecaa152a3ced4b789dd",
      "15b33d61ffce444687e22c26d7d2bc51",
      "8f39d486ebd54faf9f697fa6f1c01732",
      "a6ab689571744d2e8e1a1202f573f53d",
      "4e1794d11bce4bd3af783fe479c94278",
      "10c1eb67ca6e4314ad55d47e7994cdd5"
     ]
    },
    "outputId": "6d74a966-0c2f-4cf9-bd81-6e6fd58de49f"
   },
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "progress_bar = tqdm(total=num_training_steps, desc=\"Training Progress\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        ## Complete the training loop\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids=batch[\"input_ids\"], labels = batch[\"labels\"])\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation Phase\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "    total_eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            output = model(input_ids=batch[\"input_ids\"], labels = batch[\"labels\"])\n",
    "            loss = output.loss\n",
    "            total_eval_loss += loss.item()\n",
    "            total_batches += 1\n",
    "      ### Complete the evaluation phase\n",
    "\n",
    "    avg_loss = total_eval_loss / total_batches if total_batches > 0 else float('inf')\n",
    "    print(f\"Epoch {epoch}: Average Eval Loss: {avg_loss:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "The above training phase took about 90 min to run",
   "metadata": {
    "id": "Vlg_7_rNIMrU"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_7JA8gD7dYL"
   },
   "source": [
    "Congratulations!! On completing the training. Now don't forget to save your model and the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hqTmBLMG7dYL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "outputId": "18fe657b-b58c-4cda-8933-0db7214c1786"
   },
   "source": [
    "# Save model and tokenizer\n",
    "output_dir = \"HW2-transformer-model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCrwRPf-7dYL"
   },
   "source": [
    "## Q9) Evaluating Transformer for Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsteZEw77dYL"
   },
   "source": [
    "We will now test our trained model and analyze its performance using BLEU-1, 2, 3, 4 scores from the sacrebleu library. You will create a task evaluator for translation, load and process the test dataset, and compute the results on an existing trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we load a model trained for french to english translation. You can read more about it here: https://huggingface.co/Helsinki-NLP/opus-mt-tc-big-fr-en"
   ],
   "metadata": {
    "id": "YNP8tJ3Y9Yna"
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#pip install sentencepiece",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "checkpoint = \"Helsinki-NLP/opus-mt-tc-big-fr-en\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "metadata": {
    "id": "OUIYns7E9S2j"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize an evaluator for translation task"
   ],
   "metadata": {
    "id": "1HRtKCKh9mqc"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dR_Kc8NN7dYL"
   },
   "source": [
    "## Load Evaluator for translation\n",
    "from evaluate import evaluator\n",
    "task_evaluator = evaluator(\"translation\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL8zPaFz7dYL"
   },
   "source": [
    "We will need to change our test dataset by having specific input and target columns. Thus we will use split_translation to split the translation column into two columns 'en' and 'fr'."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NMCG74Vr7dYL"
   },
   "source": [
    "#  Implement the split function\n",
    "def split_translations(example):\n",
    "    en_text = example[\"translation\"][\"en\"]\n",
    "    fr_text = example[\"translation\"][\"fr\"]\n",
    "    example['en'] = en_text\n",
    "    example['fr'] = fr_text\n",
    "    return example"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# debug\n",
    "test_dataset"
   ],
   "metadata": {
    "id": "mQmOELHePzLj"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NpUlKUm17dYL"
   },
   "source": "test_data = test_dataset.map(split_translations)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(test_data)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Since I trained my model on my local mac, I could not use cuda\n",
    "# alternative is to use mps for mac\n",
    "import torch\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA9Vt7kF7dYL"
   },
   "source": [
    "You can now go ahead and compute the results by appropriately setting up the task_evaluator.compute()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HV6gQhFP7dYL"
   },
   "source": [
    "import sacrebleu\n",
    "import evaluate\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline= model,\n",
    "    data= test_data,\n",
    "    tokenizer= tokenizer,\n",
    "    metric=bleu_metric,\n",
    "    input_column=\"fr\",\n",
    "    label_column=\"en\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The above cell took 49 min to run"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AEv4BBNq7dYM"
   },
   "source": [
    "print(results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvPJif197dYM"
   },
   "source": [
    "## Q10) Inferencing on Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2VpQtGW7dYM"
   },
   "source": [
    "Let's check out how well this trained model's translation skills are. You can use try with a few french sentence and see how well it translates.\n",
    "\n",
    "To do so we will setup a pipline using the existing trained model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6mVfvWC7dYM"
   },
   "source": [
    "Loading the tokenizer and model for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nojJlgVf7dYM"
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "checkpoint = \"Helsinki-NLP/opus-mt-tc-big-fr-en\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53K25pUn7dYM"
   },
   "source": [
    "Setup the pipeline for translation using your model and tokenizer. You can read about pipelines here: https://huggingface.co/docs/transformers/en/main_classes/pipelines"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hKp9pNoQ7dYM"
   },
   "source": [
    "from transformers import pipeline\n",
    "# Instatiate a pipeline for Translation using the model and tokenizer\n",
    "pipeline = pipeline(\"translation_fr_to_en\", model=model, tokenizer=tokenizer)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdV-e6sM7dYM"
   },
   "source": [
    "Translate the given sentence using the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tc8Y01YC7dYM"
   },
   "source": [
    "input_text = \"J'ai mes joies, mes peines.\" # input French words/sentences\n",
    "translation_result = pipeline(input_text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5eRCXrNN7dYM"
   },
   "source": [
    "print(translation_result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_text1 = \"Chicago est cÂ´el`ebre pour ses pizzas profondes, son jazz et son architecï¿¾ture Â´epoustouflante.\"\n",
    "input_text2 = \"Jâ€™ai traduit cette phrase du franÂ¸cais vers lâ€™anglais.\"\n",
    "input_text3 = \"Vous avez maintenant terminÂ´e le deuxi`eme devoir de ce cours.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "translate1 = pipeline(input_text1)\n",
    "translate2 = pipeline(input_text2)\n",
    "translate3 = pipeline(input_text3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(translate1)\n",
    "print(translate2)\n",
    "print(translate3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note: For questions Q1-Q6, all the models were trained using Google Collab with cuda. For the rest of questions, the models were trained using Mac with MPS"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "8aecab28fc61444887162efdafc24d2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aab406e81f49463dbeb6f3336c15091a",
       "IPY_MODEL_b85d479090c0445db78fffc344f2b28a",
       "IPY_MODEL_d2275916991343fc9c3487c6f2f42f0b"
      ],
      "layout": "IPY_MODEL_8d984ce4d92b420fa6e1b82ee01cb84b"
     }
    },
    "aab406e81f49463dbeb6f3336c15091a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6554cb2c5974c918d03b531f33e9735",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_045edd3925a3497d8e121c0967ba579d",
      "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
     }
    },
    "b85d479090c0445db78fffc344f2b28a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bcd9f4e66924eb99cf5c9cf16284e53",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3445d42ac5454a0bbd2825f22cf3bf5d",
      "value": 30
     }
    },
    "d2275916991343fc9c3487c6f2f42f0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0291bb3a87d43909b64bb238f184bd1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_046061c6a2df41d5985c487bf25ec0e3",
      "value": "â€‡30/30â€‡[00:01&lt;00:00,â€‡15.23it/s]"
     }
    },
    "8d984ce4d92b420fa6e1b82ee01cb84b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6554cb2c5974c918d03b531f33e9735": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "045edd3925a3497d8e121c0967ba579d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bcd9f4e66924eb99cf5c9cf16284e53": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3445d42ac5454a0bbd2825f22cf3bf5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0291bb3a87d43909b64bb238f184bd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "046061c6a2df41d5985c487bf25ec0e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57a710bb31a14ab4a58a425f2db54e07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ef1960222d248cf8b5e5fd5831494a3",
       "IPY_MODEL_077fbf7a2b1f4dbcbe1d803d7f64e63b",
       "IPY_MODEL_5f6f5ee76013440386dcf349c9456562"
      ],
      "layout": "IPY_MODEL_c7bb677061484f79ab7ac0403445019e"
     }
    },
    "1ef1960222d248cf8b5e5fd5831494a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f54bcd623f1e44eca44cfcdce29e7251",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a6d9eabb3ce74904919a44b9d257ac59",
      "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
     }
    },
    "077fbf7a2b1f4dbcbe1d803d7f64e63b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79375ca6f18a44c9bc13e25b3cec9c07",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e2a614fc02e4029a38051f7e09854ae",
      "value": 30
     }
    },
    "5f6f5ee76013440386dcf349c9456562": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acfaf67f57dc4c90bd0bc5c4a8e9d629",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0b36c2cc6ed840c08aa615d2ae496070",
      "value": "â€‡30/30â€‡[00:00&lt;00:00,â€‡44.51it/s]"
     }
    },
    "c7bb677061484f79ab7ac0403445019e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f54bcd623f1e44eca44cfcdce29e7251": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6d9eabb3ce74904919a44b9d257ac59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79375ca6f18a44c9bc13e25b3cec9c07": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e2a614fc02e4029a38051f7e09854ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "acfaf67f57dc4c90bd0bc5c4a8e9d629": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b36c2cc6ed840c08aa615d2ae496070": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f97ac130c9684c31bbe4736005ce1428": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7da3ede06004d2cb498672266b21410",
       "IPY_MODEL_ea6182b35e584fa197014e74d1726f38",
       "IPY_MODEL_ccdca5d7aafd4b698f632ad8c637c8e4"
      ],
      "layout": "IPY_MODEL_ad410f7282534d6e8923f4e876834cea"
     }
    },
    "f7da3ede06004d2cb498672266b21410": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c43ba6e35240b287f5ddb998f6591a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_504ee3f5a3064e58aa8d0efb295033de",
      "value": "Map:â€‡100%"
     }
    },
    "ea6182b35e584fa197014e74d1726f38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8352910fdb64977b1b9d04ed3561b0a",
      "max": 2400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1193c8fb8ff040cda38d6de45f42632e",
      "value": 2400
     }
    },
    "ccdca5d7aafd4b698f632ad8c637c8e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8d880c834e445a5859e5cdecf857b78",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6e0379aaed06452796f170e7be63d2ae",
      "value": "â€‡2400/2400â€‡[00:02&lt;00:00,â€‡972.97â€‡examples/s]"
     }
    },
    "ad410f7282534d6e8923f4e876834cea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c43ba6e35240b287f5ddb998f6591a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "504ee3f5a3064e58aa8d0efb295033de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8352910fdb64977b1b9d04ed3561b0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1193c8fb8ff040cda38d6de45f42632e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8d880c834e445a5859e5cdecf857b78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e0379aaed06452796f170e7be63d2ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2ec212bb3f34cfd9149d39990f94ea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_edd44d42f249429f8ab5accbe766c4a2",
       "IPY_MODEL_df84be678d6d46fa81abb278ee93892b",
       "IPY_MODEL_09edb0f2dfc44acea70d2a9118970fa5"
      ],
      "layout": "IPY_MODEL_f2f176bc831a496ab3db566b4453cce6"
     }
    },
    "edd44d42f249429f8ab5accbe766c4a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00d06a6d8f1c4ecaa152a3ced4b789dd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_15b33d61ffce444687e22c26d7d2bc51",
      "value": "Trainingâ€‡Progress:â€‡"
     }
    },
    "df84be678d6d46fa81abb278ee93892b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f39d486ebd54faf9f697fa6f1c01732",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6ab689571744d2e8e1a1202f573f53d",
      "value": 2000
     }
    },
    "09edb0f2dfc44acea70d2a9118970fa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e1794d11bce4bd3af783fe479c94278",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_10c1eb67ca6e4314ad55d47e7994cdd5",
      "value": "â€‡4095/?â€‡[29:50&lt;00:00,â€‡â€‡2.30it/s]"
     }
    },
    "f2f176bc831a496ab3db566b4453cce6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "00d06a6d8f1c4ecaa152a3ced4b789dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15b33d61ffce444687e22c26d7d2bc51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f39d486ebd54faf9f697fa6f1c01732": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6ab689571744d2e8e1a1202f573f53d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e1794d11bce4bd3af783fe479c94278": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10c1eb67ca6e4314ad55d47e7994cdd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
