{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Making Chatbots!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Rule Based Chatbot (ELIZA)\n",
    "In this secttion, you will implement a rule-based Chatbot, ELIZA, using the provided eliza.py file. The eliza.py file contains the rules for the model to follow, you need to complete the code to utilize the file to implement a chat agent while saving the chat history."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T20:52:17.261763Z",
     "start_time": "2025-04-15T20:52:17.258953Z"
    }
   },
   "source": [
    "import eliza"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Eliza model from eliza.py"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T20:52:18.927133Z",
     "start_time": "2025-04-15T20:52:18.924184Z"
    }
   },
   "source": [
    "#eliza = eliza.FILL_IN_CODE\n",
    "eliza = eliza.Eliza()"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and open the file to save chat history"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:29:41.909052Z",
     "start_time": "2025-04-16T02:29:41.906471Z"
    }
   },
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "#now = FILL_IN_CODE\n",
    "now = datetime.now()\n",
    "\n",
    "# Format the date and time to create the file name\n",
    "file_name = f\"ELIZA_CHAT_{now.strftime('%Y_%m_%d_%H_%M_%S')}.txt\"\n",
    "f = open(file_name, \"w\")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the regex for exit\n",
    "You need to define an appropriate regex expression that searches for the appropriate words such as 'bye' or 'exit' in the user input to recognize that the user wants to end the chat"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:29:45.999878Z",
     "start_time": "2025-04-16T02:29:45.997365Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "def is_end(input_string):\n",
    "    exit_list = ['bye', 'exit', 'see you', 'chao', 'exit']\n",
    "    #pattern = re.compile(FILL_IN_CODE) # compile and find exit words\n",
    "    pattern = re.compile('|'.join(exit_list), re.IGNORECASE)\n",
    "    #if FILL_IN_CODE:\n",
    "    if pattern.search(input_string):\n",
    "        return True\n",
    "    return False"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:29:49.417420Z",
     "start_time": "2025-04-16T02:29:49.414917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# testing code\n",
    "exit_list = ['bye', 'exit', 'see you', 'chao', 'exit']\n",
    "pattern = re.compile('|'.join(exit_list), re.IGNORECASE)\n",
    "#pattern = re.compile(\"G\", re.IGNORECASE)\n",
    "if pattern.search(\"bye\"):\n",
    "    print(\"Found\")\n",
    "else:\n",
    "    print(\"Not found\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a chat loop\n",
    "In this part, you need to define a loop that asks for user input and prints the user response till the user wants to end the chat"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:32:38.424177Z",
     "start_time": "2025-04-16T02:29:59.349591Z"
    }
   },
   "source": [
    "while True:\n",
    "    user_input = input(\"User:\")\n",
    "    if is_end(user_input):\n",
    "        # Output the goodbye message, write the last inputs and outputs to the log and close the file\n",
    "        goodbye_message = \"Goodbye, please take care\"\n",
    "        print(\"Eliza:\", goodbye_message)\n",
    "        f.write(\"User: \" + user_input + \"\\n\") # Log the user's last input\n",
    "        f.write(\"Eliza: \"+ goodbye_message + \"\\n\") # Log the agent's goodbye message\n",
    "        f.close()\n",
    "        break\n",
    "    response = eliza.respond(user_input)\n",
    "    print(\"Eliza:\", response)\n",
    "    f.write(\"User: \" + user_input + \"\\n\") # Log the user's input\n",
    "    f.write(\"Eliza: \"+ response + \"\\n\") # Log the agent's response"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliza: Can you elaborate on that?\n",
      "Eliza: I see.\n",
      "Eliza: What other reasons come to mind?\n",
      "Eliza: Why do you say that you also like the taste?\n",
      "Eliza: Is that the real reason?\n",
      "Eliza: OK, but can you elaborate a bit?\n",
      "Eliza: How do you feel when you say that?\n",
      "Eliza: When you feel warm, what do you do?\n",
      "Eliza: Can you elaborate on that?\n",
      "Eliza: Goodbye, please take care\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Congrats, you are done with part 1. You now need to simply test out your model for 3 chat conversations (minimum 10 utterances in each conversation) and report the results of the human survey."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Corpus Based Chatbot\n",
    "\n",
    "In this section, you will implement a corpus-based chatbot using the given dialogues.csv corpus. As a part of this task, you will first load the dataset, compute the sentence embeddings for the corpus sentences using the SentenceTransformer Library and then utilize these embeddings for retrieving the most appropriate response.\n",
    "\n",
    "Note: This part will be slow to run on a CPU based environment (upto 5 minutes), however, it should be very fast on a Colab GPU environment (close to 5 seconds), because of the use of transformer architectures."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T18:44:43.395375Z",
     "start_time": "2025-04-14T18:44:42.281646Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -U sentence-transformers\n",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\r\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.49.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\r\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.29.3)\r\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\r\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.11.0)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\r\n",
      "Downloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\r\n",
      "Installing collected packages: sentence-transformers\r\n",
      "Successfully installed sentence-transformers-4.0.2\r\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:37:36.175998Z",
     "start_time": "2025-04-16T02:37:36.173981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Load the dialogues.csv file using the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:37:39.263834Z",
     "start_time": "2025-04-16T02:37:39.190741Z"
    }
   },
   "source": [
    "data = pd.read_csv(\"dialogues.csv\")\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       emotion                                               User  \\\n",
       "0  sentimental  I remember going to see the fireworks with my ...   \n",
       "1  sentimental                This was a best friend. I miss her.   \n",
       "2  sentimental                                 We no longer talk.   \n",
       "3  sentimental  Was this a friend you were in love with, or ju...   \n",
       "4  sentimental                                Where has she gone?   \n",
       "\n",
       "                                               Agent  \n",
       "0  Was this a friend you were in love with, or ju...  \n",
       "1                                Where has she gone?  \n",
       "2  Oh was this something that happened because of...  \n",
       "3                This was a best friend. I miss her.  \n",
       "4                                 We no longer talk.  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>User</th>\n",
       "      <th>Agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>Where has she gone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>Oh was this something that happened because of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentimental</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>We no longer talk.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the SentenceTransformer model\n",
    "docs: https://sbert.net/docs/sentence_transformer/usage/usage.html\n",
    "\n",
    "Load the ```all-MiniLM-L6-v2``` sentence transformer model for computing the contextual embeddings."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:37:46.726077Z",
     "start_time": "2025-04-16T02:37:44.206189Z"
    }
   },
   "source": [
    "#model = FILL_IN_CODE\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the sentence embeddings\n",
    "For the 'User' column of the dataset, compute the sentence embeddings using the sentence transformer model."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:38:16.654706Z",
     "start_time": "2025-04-16T02:37:52.866568Z"
    }
   },
   "source": [
    "user_dialogues = data['User'].tolist() # sentences to encode\n",
    "#user_embeddings = model.FILL_IN_CODE\n",
    "user_embeddings = model.encode(user_dialogues) # calculate embeddings"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The above line took about 30s run on Mac M4."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the agent response\n",
    "In the get_response() function, utilize the user_embeddings to retrieve the most similar instance from the data point using cosine similarity. For the selected data point, return the corresponding response in the 'Agent' column of the data as the agent's reponse."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:39:33.991807Z",
     "start_time": "2025-04-16T02:39:33.989590Z"
    }
   },
   "source": [
    "def get_response(user_input, data, model, user_embeddings):\n",
    "    # Convert the input of the user to its sentence embedding\n",
    "    input_embedding = model.encode(user_input)\n",
    "    \n",
    "    # Compute cosine similarities between user input embeddings and user embeddings (based on the data)\n",
    "    cosine_scores = util.pytorch_cos_sim(input_embedding, user_embeddings)\n",
    "    \n",
    "    # Find the index of the highest cosine similarity using np.argmax.\n",
    "    best_match_idx = np.argmax(cosine_scores.numpy())\n",
    "    \n",
    "    # Return the corresponding string for the 'Agent' column\n",
    "    return data['Agent'].iloc[best_match_idx]\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and open the file to save chat history"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:42:45.399191Z",
     "start_time": "2025-04-16T02:42:45.396446Z"
    }
   },
   "source": [
    "### Define and open the file to save chat history\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# Format the date and time to create the file name\n",
    "file_name = f\"CORPUS_CHAT_{now.strftime('%Y_%m_%d_%H_%M_%S')}.txt\"\n",
    "f = open(file_name, \"w\")"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a chat loop\n",
    "In this part, you need to define a loop that asks for user input and prints the user response till the user wants to end the chat. Utilize the same regex expression as before to identify when the user wants to end the chat."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T02:44:44.194632Z",
     "start_time": "2025-04-16T02:42:47.445230Z"
    }
   },
   "source": [
    "while True:\n",
    "    user_input = input(\"User:\")\n",
    "    if is_end(user_input):\n",
    "        # Output the goodbye message, write the last inputs and outputs to the log and close the file\n",
    "        goodbye_message = \"Goodbye, please take care\"\n",
    "        print(\"Corpus Agent:\", goodbye_message)\n",
    "        f.write(\"User:\" + user_input + \"\\n\") # Log the user's last input\n",
    "        f.write(\"Corpus Agent:\" + goodbye_message + \"\\n\") # Log the agent's goodbye message\n",
    "        f.close()\n",
    "        break\n",
    "    response = get_response(user_input, data, model, user_embeddings)\n",
    "    print(\"Corpus Agent:\", response)\n",
    "    f.write(\"User: \" + user_input + \"\\n\") # Log the user's input\n",
    "    f.write(\"Corpus Agent: \"+ response + \"\\n\") # Log the agent's response"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Agent: You would have been mad at me this morning!\n",
      "Corpus Agent: I am happy for you\n",
      "Corpus Agent: A large caramel frappe with whip cream. It's delicious.\n",
      "Corpus Agent: Are the coffees there expensive?\n",
      "Corpus Agent: What kind of coffee will you get?\n",
      "Corpus Agent: A large caramel frappe with whip cream. It's delicious.\n",
      "Corpus Agent: Goodbye, please take care\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Congrats, you are done with part 2. You now need to simply test out your model for 3 chat conversations (minimum 10 utterances in each conversation) and report the results of the human survey."
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
