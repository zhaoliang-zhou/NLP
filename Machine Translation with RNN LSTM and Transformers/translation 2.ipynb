{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaOSrvct7dX8"
   },
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install ðŸ¤— Transformers and ðŸ¤— Datasets. Uncomment the following cell and run it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8GwJkoNj7dYA",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5c28db5b-c254-4456-f023-d578207185e1",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:03:58.354587Z",
     "start_time": "2025-03-13T18:03:57.611722Z"
    }
   },
   "source": " !pip install transformers datasets evaluate sacrebleu torchtext",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.49.0)\r\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.3.2)\r\n",
      "Requirement already satisfied: evaluate in /opt/anaconda3/lib/python3.12/site-packages (0.4.3)\r\n",
      "Requirement already satisfied: sacrebleu in /opt/anaconda3/lib/python3.12/site-packages (2.5.1)\r\n",
      "Requirement already satisfied: torchtext in /opt/anaconda3/lib/python3.12/site-packages (0.18.0)\r\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.29.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.0)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\r\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\r\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\r\n",
      "Requirement already satisfied: portalocker in /opt/anaconda3/lib/python3.12/site-packages (from sacrebleu) (3.1.1)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/anaconda3/lib/python3.12/site-packages (from sacrebleu) (0.9.0)\r\n",
      "Requirement already satisfied: colorama in /opt/anaconda3/lib/python3.12/site-packages (from sacrebleu) (0.4.6)\r\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.12/site-packages (from sacrebleu) (5.2.1)\r\n",
      "Requirement already satisfied: torch>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchtext) (2.6.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.12.14)\r\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (75.1.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.3.0->torchtext) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.3)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qhd_GW5J7dYB",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:11:55.613023Z",
     "start_time": "2025-03-13T20:11:55.611465Z"
    }
   },
   "source": [
    "from tqdm.auto import tqdm"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omSuPoLY7dYB"
   },
   "source": [
    "## Q1: Dataset Preparation (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VtQHtK5j7dYB",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:11:57.341409Z",
     "start_time": "2025-03-13T20:11:57.339646Z"
    }
   },
   "source": [
    "from datasets import load_dataset"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRQ7Hsrj7dYC"
   },
   "source": [
    "We use the ```load_dataset()``` function to download the dataset. Replace the dummy arguments to download the wmt14 dataset for fr-en translation as provided here: https://huggingface.co/datasets/wmt/wmt14"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "klc-jtLi7dYC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243,
     "referenced_widgets": [
      "8aecab28fc61444887162efdafc24d2b",
      "aab406e81f49463dbeb6f3336c15091a",
      "b85d479090c0445db78fffc344f2b28a",
      "d2275916991343fc9c3487c6f2f42f0b",
      "8d984ce4d92b420fa6e1b82ee01cb84b",
      "d6554cb2c5974c918d03b531f33e9735",
      "045edd3925a3497d8e121c0967ba579d",
      "8bcd9f4e66924eb99cf5c9cf16284e53",
      "3445d42ac5454a0bbd2825f22cf3bf5d",
      "e0291bb3a87d43909b64bb238f184bd1",
      "046061c6a2df41d5985c487bf25ec0e3"
     ]
    },
    "outputId": "c1dbea6f-8039-47d6-a89a-dbb25b1aa53f",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:12:07.792932Z",
     "start_time": "2025-03-13T20:11:59.552718Z"
    }
   },
   "source": [
    "dataset = load_dataset(\"wmt14\", \"fr-en\", split='train[:15000]')\n",
    "dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "754428c431c243d2bfe3a2e5ee979546"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 15000\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPhRx3w8MrC9",
    "outputId": "79724e59-d2c5-4e75-d67d-09c4f2c0f8d8",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:12:10.449533Z",
     "start_time": "2025-03-13T20:12:10.447908Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 15000\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OajGgO-R7dYC"
   },
   "source": [
    "Now, we split the dataset into training and testing splits. This is done using the ```train_test_split``` function. Replace the dummy arguments with appropriate parameters."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9oCpCOAv7dYC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1d03ba6d-ddc2-4f11-ca2a-aa299e49cc97",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:12:14.049091Z",
     "start_time": "2025-03-13T20:12:14.045038Z"
    }
   },
   "source": [
    "split_datasets = dataset.train_test_split(train_size=0.8, seed=2025)\n",
    "split_datasets\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nU3rB0eR7dYD"
   },
   "source": [
    "Define the test dataset as follows:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F0KvRQL07dYD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "57245cf1-7f46-4ed0-a811-11b573ba949d",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:12:17.202491Z",
     "start_time": "2025-03-13T20:12:17.200294Z"
    }
   },
   "source": [
    "test_dataset = split_datasets[\"test\"]\n",
    "test_dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykFRxwh57dYD"
   },
   "source": [
    "Now, follow the same process to split the train dataset to training and validation splits."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kynutdwu7dYD",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "57a710bb31a14ab4a58a425f2db54e07",
      "1ef1960222d248cf8b5e5fd5831494a3",
      "077fbf7a2b1f4dbcbe1d803d7f64e63b",
      "5f6f5ee76013440386dcf349c9456562",
      "c7bb677061484f79ab7ac0403445019e",
      "f54bcd623f1e44eca44cfcdce29e7251",
      "a6d9eabb3ce74904919a44b9d257ac59",
      "79375ca6f18a44c9bc13e25b3cec9c07",
      "3e2a614fc02e4029a38051f7e09854ae",
      "acfaf67f57dc4c90bd0bc5c4a8e9d629",
      "0b36c2cc6ed840c08aa615d2ae496070"
     ]
    },
    "outputId": "718afc6c-aacf-47cd-9d5f-b40eeee2c0ac",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:12:29.399060Z",
     "start_time": "2025-03-13T20:12:20.184937Z"
    }
   },
   "source": [
    "# load the validation set\n",
    "split_to_val = load_dataset(\"wmt14\", \"fr-en\", split='validation')\n",
    "# further split the train set into 0.8 train and 0.2 evaluation datasets\n",
    "train_eval_split = split_datasets[\"train\"].train_test_split(train_size=0.8, seed=2025)\n",
    "train_dataset = train_eval_split[\"train\"]\n",
    "eval_dataset = train_eval_split[\"test\"]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "225662fb1812422baa7a86e080552e68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xz4dcIUFMrC-",
    "outputId": "5cc81dc1-ba31-49c4-8c53-56367f135d1c",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:12:31.233693Z",
     "start_time": "2025-03-13T20:12:31.231438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test code\n",
    "train_eval_split"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 9600\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 2400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2J7AypmH7dYD"
   },
   "source": [
    "## Q2 Prepare for training RNNs (10)\n",
    "In this part, you are required to define the tokenizers for english and french, tokenize the data, and define the dataloaders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaR1qKZs7dYD"
   },
   "source": [
    "Choose and initialize the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qfFHDk3D7dYD",
    "ExecuteTime": {
     "end_time": "2025-03-12T16:49:35.503852Z",
     "start_time": "2025-03-12T16:49:31.228382Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased') # CHOOSE AN APPROPRIATE MULTILINGUAL MODEL such as https://huggingface.co/google-bert/bert-base-multilingual-cased"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITKX-cza7dYD"
   },
   "source": [
    "You will need to create a pytorch dataset to process the tokens in the required format. Complete the implementation of the dataset."
   ]
  },
  {
   "metadata": {
    "id": "mmwtmvc3MrC-"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uCKYlKu07dYD",
    "ExecuteTime": {
     "end_time": "2025-03-12T18:26:36.816386Z",
     "start_time": "2025-03-12T18:26:36.813458Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, dataset, input_size, output_size):\n",
    "        source_texts = [text[\"translation\"]['fr'] for text in dataset]\n",
    "        target_texts = [text[\"translation\"]['en'] for text in dataset]\n",
    "        self.source_sentences = tokenizer(source_texts, padding='max_length', truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
    "        self.target_sentences = tokenizer(target_texts, padding='max_length', truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.source_sentences[idx], self.target_sentences[idx]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUl1vQj07dYE"
   },
   "source": [
    "Initialize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u-Hqb62L7dYE",
    "ExecuteTime": {
     "end_time": "2025-03-12T18:26:45.395844Z",
     "start_time": "2025-03-12T18:26:41.755412Z"
    }
   },
   "source": [
    "# pick a random vocab size\n",
    "vocab_size = tokenizer.vocab_size\n",
    "train_dataset_rnn = TranslationDataset(train_dataset, vocab_size, vocab_size)\n",
    "eval_dataset_rnn = TranslationDataset(eval_dataset, vocab_size, vocab_size)\n",
    "test_dataset_rnn = TranslationDataset(test_dataset, vocab_size, vocab_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T18:26:47.044225Z",
     "start_time": "2025-03-12T18:26:47.041873Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hr4Vv58MMrC-",
    "outputId": "c7f35155-d9b6-42c6-a4b9-682ae3e23151"
   },
   "cell_type": "code",
   "source": [
    "# test code\n",
    "len(test_dataset_rnn)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-JfiZAH7dYE"
   },
   "source": [
    "Get the vocab size from the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aR1CEzJN7dYE",
    "ExecuteTime": {
     "end_time": "2025-03-12T18:26:49.259245Z",
     "start_time": "2025-03-12T18:26:49.256878Z"
    }
   },
   "source": [
    "vocab_size = tokenizer.vocab_size # This size is used somewhere in the model, think."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8uvrc0R7dYE"
   },
   "source": [
    "Initialize and define the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8W3qVX2N7dYE",
    "ExecuteTime": {
     "end_time": "2025-03-12T18:26:53.714823Z",
     "start_time": "2025-03-12T18:26:53.712348Z"
    }
   },
   "source": [
    "#Instantiate the DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "# recommende batch size using powers of 2 - effecient memory usage\n",
    "BATCH_SIZE = 8\n",
    "train_dataloader = DataLoader(train_dataset_rnn, batch_size=BATCH_SIZE, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_dataset_rnn, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_dataset_rnn, batch_size=BATCH_SIZE)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T19:54:05.927779Z",
     "start_time": "2025-03-12T19:54:05.924428Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47aHE1pkMrC_",
    "outputId": "e2893c2b-64ee-4a09-86ea-d32a027cbaa2"
   },
   "cell_type": "code",
   "source": [
    "# test code\n",
    "len(train_dataloader)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X03nj-qd7dYE"
   },
   "source": [
    "## Q3: Implementing RNNs (10)\n",
    "Define the RNN model as an encoder-decoder RNN for the task of translation in the cell below. You may refer: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6iYwjZXt7dYE",
    "ExecuteTime": {
     "end_time": "2025-03-12T20:06:53.318491Z",
     "start_time": "2025-03-12T20:06:53.316543Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kZcyOabn7dYE",
    "ExecuteTime": {
     "end_time": "2025-03-12T20:06:54.649571Z",
     "start_time": "2025-03-12T20:06:54.644551Z"
    }
   },
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_p=0.5):\n",
    "        super(Seq2SeqRNN, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size) # embedding layer\n",
    "        self.encoder = nn.RNN(hidden_size, hidden_size, batch_first=True) # encoder\n",
    "        self.dropout = nn.Dropout(p=dropout_p) # drop out layer following tutorial\n",
    "        self.decoder = nn.RNN(hidden_size, hidden_size, batch_first=True) # decoder\n",
    "        self.out = nn.Linear(hidden_size, output_size) #output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        encoder_outputs, hidden = self.encoder(embedded)\n",
    "        decoder_outputs, _ = self.decoder(encoder_outputs, hidden)\n",
    "        output = self.out(decoder_outputs)\n",
    "        return output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SnP9NUtK7dYE",
    "ExecuteTime": {
     "end_time": "2025-03-12T20:06:56.978507Z",
     "start_time": "2025-03-12T20:06:56.715424Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1542aee2-971a-43d1-b97b-2514a0a77a43"
   },
   "source": [
    "input_size = tokenizer.vocab_size\n",
    "output_size = tokenizer.vocab_size\n",
    "model = Seq2SeqRNN(input_size = input_size, hidden_size= 128, output_size = output_size)\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Seq2SeqRNN(\n",
       "  (embedding): Embedding(119547, 128)\n",
       "  (encoder): RNN(128, 128, batch_first=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (decoder): RNN(128, 128, batch_first=True)\n",
       "  (out): Linear(in_features=128, out_features=119547, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MZb5OZc7dYE"
   },
   "source": [
    "## Q4: Training RNNs (15)\n",
    "In this question, you will define the hyperparameters, loss and optimizer for training. You will then implement a custom training loop."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "INYhxibp7dYE",
    "ExecuteTime": {
     "end_time": "2025-03-12T20:07:02.414213Z",
     "start_time": "2025-03-12T20:07:02.412359Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4a01c45c-0fca-4177-c19f-e448a0596cec"
   },
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "torch.cuda.is_available()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7cPIUCd7dYE"
   },
   "source": [
    "define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FeCoP4DC7dYE",
    "ExecuteTime": {
     "end_time": "2025-03-12T20:07:04.107063Z",
     "start_time": "2025-03-12T20:07:04.080907Z"
    }
   },
   "source": [
    "#from torch.optim import IMPORT_OPTIMIZER\n",
    "import torch.optim as optim\n",
    "#from torch.nn import IMPORT_LOSS_FUNCTION\n",
    "\n",
    "num_train_epochs = 3 # define epochs for training\n",
    "num_training_steps = num_train_epochs * len(train_dataloader)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)# YOUR LOSS FUNCTION\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01) # YOUR OPTIMIZER HERE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2w-eirJ7dYE"
   },
   "source": [
    "Write the training loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "waBwBdVx7dYE",
    "ExecuteTime": {
     "start_time": "2025-03-12T20:07:06.098632Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "99f0f290-48ed-4819-f212-47a3c97a6a62"
   },
   "source": [
    "from tqdm import tqdm\n",
    "progress_bar = tqdm(total=num_training_steps, desc=\"Training Progress\")\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_src, batch_tgt in train_dataloader:\n",
    "        ## Complete the training loop\n",
    "        optimizer.zero_grad()\n",
    "        batch_src = batch_src.to(torch.device('cuda'))\n",
    "        batch_tgt = batch_tgt.to(torch.device('cuda'))\n",
    "        output = model(batch_src)\n",
    "        loss = criterion(output.view(-1, output_size), batch_tgt.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation Phase\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    total_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_src, batch_tgt in eval_dataloader:\n",
    "            batch_src = batch_src.to(torch.device('cuda'))\n",
    "            batch_tgt = batch_tgt.to(torch.device('cuda'))\n",
    "            output = model(batch_src)\n",
    "            loss = criterion(output.view(-1, output_size), batch_tgt.view(-1))\n",
    "            total_eval_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "\n",
    "      ### Complete the evaluation phase\n",
    "\n",
    "    avg_loss = total_eval_loss / total_batches if total_batches > 0 else float(\"inf\")\n",
    "    print(f\"Epoch {epoch}: Average Eval Loss: {avg_loss:.4f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training Progress:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1201/3600 [04:19<4:48:50,  7.22s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0: Average Eval Loss: 7.1178\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training Progress:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2401/3600 [08:39<2:25:51,  7.30s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1: Average Eval Loss: 7.0280\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3600/3600 [12:36<00:00,  5.09it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2: Average Eval Loss: 7.2747\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-e1x_Lm7dYF"
   },
   "source": [
    "## Q5: Evaluating RNNs for Machine Translation (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrE3V_P17dYF"
   },
   "source": [
    "Implement the calculation of BLEU-1,2,3,4 scores using the ```sacrebleu``` library for the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import sacrebleu"
   ],
   "metadata": {
    "id": "1l5FBni2l2DT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xddoMFY17dYF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c025c868-6a98-470f-99a2-54d0fe2030b7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  0%|          | 0/375 [00:00<?, ?it/s]\u001B[A\n",
      "  0%|          | 1/375 [00:00<01:13,  5.07it/s]\u001B[A\n",
      "  1%|          | 2/375 [00:00<01:22,  4.50it/s]\u001B[A\n",
      "  1%|          | 3/375 [00:00<01:25,  4.34it/s]\u001B[A\n",
      "  1%|          | 4/375 [00:00<01:25,  4.32it/s]\u001B[A\n",
      "  1%|â–         | 5/375 [00:01<01:28,  4.19it/s]\u001B[A\n",
      "  2%|â–         | 6/375 [00:01<01:25,  4.33it/s]\u001B[A\n",
      "  2%|â–         | 7/375 [00:01<01:20,  4.55it/s]\u001B[A\n",
      "  2%|â–         | 8/375 [00:01<01:21,  4.49it/s]\u001B[A\n",
      "  2%|â–         | 9/375 [00:01<01:18,  4.67it/s]\u001B[A\n",
      "  3%|â–Ž         | 10/375 [00:02<01:20,  4.51it/s]\u001B[A\n",
      "  3%|â–Ž         | 11/375 [00:02<01:15,  4.81it/s]\u001B[A\n",
      "  3%|â–Ž         | 12/375 [00:02<01:10,  5.14it/s]\u001B[A\n",
      "  3%|â–Ž         | 13/375 [00:02<01:07,  5.34it/s]\u001B[A\n",
      "  4%|â–Ž         | 14/375 [00:02<01:04,  5.60it/s]\u001B[A\n",
      "  4%|â–         | 15/375 [00:03<01:01,  5.81it/s]\u001B[A\n",
      "  4%|â–         | 16/375 [00:03<00:59,  6.03it/s]\u001B[A\n",
      "  5%|â–         | 17/375 [00:03<00:56,  6.35it/s]\u001B[A\n",
      "  5%|â–         | 18/375 [00:03<00:54,  6.52it/s]\u001B[A\n",
      "  5%|â–Œ         | 19/375 [00:03<00:53,  6.70it/s]\u001B[A\n",
      "  5%|â–Œ         | 20/375 [00:03<00:52,  6.80it/s]\u001B[A\n",
      "  6%|â–Œ         | 21/375 [00:03<00:50,  6.98it/s]\u001B[A\n",
      "  6%|â–Œ         | 22/375 [00:04<00:50,  7.02it/s]\u001B[A\n",
      "  6%|â–Œ         | 23/375 [00:04<00:51,  6.80it/s]\u001B[A\n",
      "  6%|â–‹         | 24/375 [00:04<00:55,  6.29it/s]\u001B[A\n",
      "  7%|â–‹         | 25/375 [00:04<01:04,  5.39it/s]\u001B[A\n",
      "  7%|â–‹         | 26/375 [00:04<01:13,  4.73it/s]\u001B[A\n",
      "  7%|â–‹         | 27/375 [00:05<01:06,  5.24it/s]\u001B[A\n",
      "  8%|â–Š         | 29/375 [00:05<00:50,  6.84it/s]\u001B[A\n",
      "  8%|â–Š         | 31/375 [00:05<00:42,  8.03it/s]\u001B[A\n",
      "  9%|â–‰         | 33/375 [00:05<00:38,  8.89it/s]\u001B[A\n",
      "  9%|â–‰         | 35/375 [00:05<00:35,  9.53it/s]\u001B[A\n",
      " 10%|â–‰         | 36/375 [00:05<00:35,  9.59it/s]\u001B[A\n",
      " 10%|â–ˆ         | 38/375 [00:06<00:33,  9.92it/s]\u001B[A\n",
      " 11%|â–ˆ         | 40/375 [00:06<00:32, 10.19it/s]\u001B[A\n",
      " 11%|â–ˆ         | 42/375 [00:06<00:31, 10.42it/s]\u001B[A\n",
      " 12%|â–ˆâ–        | 44/375 [00:06<00:31, 10.57it/s]\u001B[A\n",
      " 12%|â–ˆâ–        | 46/375 [00:06<00:30, 10.65it/s]\u001B[A\n",
      " 13%|â–ˆâ–Ž        | 48/375 [00:07<00:31, 10.48it/s]\u001B[A\n",
      " 13%|â–ˆâ–Ž        | 50/375 [00:07<00:30, 10.52it/s]\u001B[A\n",
      " 14%|â–ˆâ–        | 52/375 [00:07<00:30, 10.66it/s]\u001B[A\n",
      " 14%|â–ˆâ–        | 54/375 [00:07<00:30, 10.68it/s]\u001B[A\n",
      " 15%|â–ˆâ–        | 56/375 [00:07<00:29, 10.77it/s]\u001B[A\n",
      " 15%|â–ˆâ–Œ        | 58/375 [00:07<00:29, 10.72it/s]\u001B[A\n",
      " 16%|â–ˆâ–Œ        | 60/375 [00:08<00:29, 10.69it/s]\u001B[A\n",
      " 17%|â–ˆâ–‹        | 62/375 [00:08<00:29, 10.67it/s]\u001B[A\n",
      " 17%|â–ˆâ–‹        | 64/375 [00:08<00:29, 10.69it/s]\u001B[A\n",
      " 18%|â–ˆâ–Š        | 66/375 [00:08<00:28, 10.83it/s]\u001B[A\n",
      " 18%|â–ˆâ–Š        | 68/375 [00:08<00:28, 10.84it/s]\u001B[A\n",
      " 19%|â–ˆâ–Š        | 70/375 [00:09<00:28, 10.74it/s]\u001B[A\n",
      " 19%|â–ˆâ–‰        | 72/375 [00:09<00:28, 10.80it/s]\u001B[A\n",
      " 20%|â–ˆâ–‰        | 74/375 [00:09<00:27, 10.84it/s]\u001B[A\n",
      " 20%|â–ˆâ–ˆ        | 76/375 [00:09<00:27, 10.91it/s]\u001B[A\n",
      " 21%|â–ˆâ–ˆ        | 78/375 [00:09<00:27, 10.92it/s]\u001B[A\n",
      " 21%|â–ˆâ–ˆâ–       | 80/375 [00:09<00:26, 10.96it/s]\u001B[A\n",
      " 22%|â–ˆâ–ˆâ–       | 82/375 [00:10<00:26, 10.95it/s]\u001B[A\n",
      " 22%|â–ˆâ–ˆâ–       | 84/375 [00:10<00:26, 10.96it/s]\u001B[A\n",
      " 23%|â–ˆâ–ˆâ–Ž       | 86/375 [00:10<00:26, 10.86it/s]\u001B[A\n",
      " 23%|â–ˆâ–ˆâ–Ž       | 88/375 [00:10<00:26, 10.90it/s]\u001B[A\n",
      " 24%|â–ˆâ–ˆâ–       | 90/375 [00:10<00:26, 10.94it/s]\u001B[A\n",
      " 25%|â–ˆâ–ˆâ–       | 92/375 [00:11<00:25, 10.91it/s]\u001B[A\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 94/375 [00:11<00:25, 10.98it/s]\u001B[A\n",
      " 26%|â–ˆâ–ˆâ–Œ       | 96/375 [00:11<00:25, 10.99it/s]\u001B[A\n",
      " 26%|â–ˆâ–ˆâ–Œ       | 98/375 [00:11<00:25, 11.00it/s]\u001B[A\n",
      " 27%|â–ˆâ–ˆâ–‹       | 100/375 [00:11<00:25, 10.98it/s]\u001B[A\n",
      " 27%|â–ˆâ–ˆâ–‹       | 102/375 [00:11<00:24, 10.96it/s]\u001B[A\n",
      " 28%|â–ˆâ–ˆâ–Š       | 104/375 [00:12<00:25, 10.75it/s]\u001B[A\n",
      " 28%|â–ˆâ–ˆâ–Š       | 106/375 [00:12<00:25, 10.70it/s]\u001B[A\n",
      " 29%|â–ˆâ–ˆâ–‰       | 108/375 [00:12<00:27,  9.59it/s]\u001B[A\n",
      " 29%|â–ˆâ–ˆâ–‰       | 109/375 [00:12<00:28,  9.17it/s]\u001B[A\n",
      " 29%|â–ˆâ–ˆâ–‰       | 110/375 [00:12<00:29,  8.91it/s]\u001B[A\n",
      " 30%|â–ˆâ–ˆâ–‰       | 111/375 [00:13<00:30,  8.65it/s]\u001B[A\n",
      " 30%|â–ˆâ–ˆâ–‰       | 112/375 [00:13<00:31,  8.26it/s]\u001B[A\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 113/375 [00:13<00:32,  8.10it/s]\u001B[A\n",
      " 30%|â–ˆâ–ˆâ–ˆ       | 114/375 [00:13<00:32,  8.11it/s]\u001B[A\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 115/375 [00:13<00:32,  7.96it/s]\u001B[A\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 116/375 [00:13<00:32,  7.93it/s]\u001B[A\n",
      " 31%|â–ˆâ–ˆâ–ˆ       | 117/375 [00:13<00:32,  7.89it/s]\u001B[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 118/375 [00:13<00:32,  7.94it/s]\u001B[A\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 119/375 [00:14<00:32,  7.84it/s]\u001B[A\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 120/375 [00:14<00:34,  7.47it/s]\u001B[A\n",
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 121/375 [00:14<00:33,  7.64it/s]\u001B[A\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 122/375 [00:14<00:33,  7.57it/s]\u001B[A\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 123/375 [00:14<00:32,  7.83it/s]\u001B[A\n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 125/375 [00:14<00:27,  8.97it/s]\u001B[A\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 127/375 [00:14<00:26,  9.52it/s]\u001B[A\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 129/375 [00:15<00:26,  9.35it/s]\u001B[A\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–      | 131/375 [00:15<00:25,  9.76it/s]\u001B[A\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 133/375 [00:15<00:36,  6.54it/s]\u001B[A\n",
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 135/375 [00:16<00:31,  7.51it/s]\u001B[A\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 137/375 [00:16<00:29,  8.18it/s]\u001B[A\n",
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 139/375 [00:16<00:26,  8.84it/s]\u001B[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 141/375 [00:16<00:24,  9.37it/s]\u001B[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 143/375 [00:16<00:23,  9.79it/s]\u001B[A\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–Š      | 145/375 [00:16<00:22, 10.13it/s]\u001B[A\n",
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 147/375 [00:17<00:21, 10.37it/s]\u001B[A\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–‰      | 149/375 [00:17<00:21, 10.30it/s]\u001B[A\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 151/375 [00:17<00:21, 10.49it/s]\u001B[A\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 153/375 [00:17<00:21, 10.49it/s]\u001B[A\n",
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 155/375 [00:17<00:20, 10.58it/s]\u001B[A\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 157/375 [00:18<00:20, 10.55it/s]\u001B[A\n",
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 159/375 [00:18<00:20, 10.52it/s]\u001B[A\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 161/375 [00:18<00:20, 10.67it/s]\u001B[A\n",
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 163/375 [00:18<00:19, 10.71it/s]\u001B[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 165/375 [00:18<00:19, 10.76it/s]\u001B[A\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 167/375 [00:19<00:19, 10.75it/s]\u001B[A\n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 169/375 [00:19<00:19, 10.77it/s]\u001B[A\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 171/375 [00:19<00:19, 10.61it/s]\u001B[A\n",
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 173/375 [00:19<00:19, 10.62it/s]\u001B[A\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 175/375 [00:19<00:18, 10.72it/s]\u001B[A\n",
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 177/375 [00:19<00:18, 10.79it/s]\u001B[A\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 179/375 [00:20<00:18, 10.83it/s]\u001B[A\n",
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 181/375 [00:20<00:18, 10.52it/s]\u001B[A\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 183/375 [00:20<00:18, 10.64it/s]\u001B[A\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 185/375 [00:20<00:17, 10.73it/s]\u001B[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 187/375 [00:20<00:17, 10.77it/s]\u001B[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 189/375 [00:21<00:17, 10.61it/s]\u001B[A\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 191/375 [00:21<00:17, 10.70it/s]\u001B[A\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 193/375 [00:21<00:17, 10.63it/s]\u001B[A\n",
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 195/375 [00:21<00:16, 10.71it/s]\u001B[A\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 197/375 [00:21<00:16, 10.79it/s]\u001B[A\n",
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 199/375 [00:22<00:16, 10.79it/s]\u001B[A\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 201/375 [00:22<00:16, 10.74it/s]\u001B[A\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 203/375 [00:22<00:16, 10.58it/s]\u001B[A\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 205/375 [00:22<00:15, 10.68it/s]\u001B[A\n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 207/375 [00:22<00:15, 10.75it/s]\u001B[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 209/375 [00:22<00:15, 10.80it/s]\u001B[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 211/375 [00:23<00:15, 10.81it/s]\u001B[A\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 213/375 [00:23<00:15, 10.80it/s]\u001B[A\n",
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 215/375 [00:23<00:15, 10.59it/s]\u001B[A\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 217/375 [00:23<00:14, 10.72it/s]\u001B[A\n",
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 219/375 [00:23<00:14, 10.78it/s]\u001B[A\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 221/375 [00:24<00:14, 10.80it/s]\u001B[A\n",
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 223/375 [00:24<00:14, 10.77it/s]\u001B[A\n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 225/375 [00:24<00:14, 10.62it/s]\u001B[A\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 227/375 [00:24<00:14, 10.04it/s]\u001B[A\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 229/375 [00:24<00:15,  9.20it/s]\u001B[A\n",
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/375 [00:25<00:16,  8.91it/s]\u001B[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 231/375 [00:25<00:16,  8.64it/s]\u001B[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 232/375 [00:25<00:17,  8.39it/s]\u001B[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 233/375 [00:25<00:17,  8.15it/s]\u001B[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 234/375 [00:25<00:17,  8.05it/s]\u001B[A\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 235/375 [00:25<00:17,  8.04it/s]\u001B[A\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 236/375 [00:25<00:17,  8.05it/s]\u001B[A\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 237/375 [00:25<00:17,  8.05it/s]\u001B[A\n",
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 238/375 [00:26<00:17,  7.99it/s]\u001B[A\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 239/375 [00:26<00:17,  7.90it/s]\u001B[A\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 240/375 [00:26<00:17,  7.88it/s]\u001B[A\n",
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 241/375 [00:26<00:17,  7.82it/s]\u001B[A\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 242/375 [00:26<00:17,  7.80it/s]\u001B[A\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 243/375 [00:26<00:16,  7.78it/s]\u001B[A\n",
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 245/375 [00:26<00:14,  8.87it/s]\u001B[A\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 247/375 [00:27<00:13,  9.47it/s]\u001B[A\n",
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 249/375 [00:27<00:12,  9.93it/s]\u001B[A\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 251/375 [00:27<00:12, 10.20it/s]\u001B[A\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 253/375 [00:27<00:11, 10.28it/s]\u001B[A\n",
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 255/375 [00:27<00:11, 10.51it/s]\u001B[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 257/375 [00:28<00:11, 10.62it/s]\u001B[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 259/375 [00:28<00:10, 10.71it/s]\u001B[A\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 261/375 [00:28<00:10, 10.78it/s]\u001B[A\n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 263/375 [00:28<00:10, 10.64it/s]\u001B[A\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 265/375 [00:28<00:10, 10.76it/s]\u001B[A\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 267/375 [00:28<00:09, 10.84it/s]\u001B[A\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 269/375 [00:29<00:09, 10.93it/s]\u001B[A\n",
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 271/375 [00:29<00:09, 10.88it/s]\u001B[A\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 273/375 [00:29<00:09, 10.95it/s]\u001B[A\n",
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 275/375 [00:29<00:10,  9.93it/s]\u001B[A\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 277/375 [00:30<00:11,  8.60it/s]\u001B[A\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 278/375 [00:30<00:11,  8.38it/s]\u001B[A\n",
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 279/375 [00:30<00:11,  8.19it/s]\u001B[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 280/375 [00:30<00:11,  7.98it/s]\u001B[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 281/375 [00:30<00:12,  7.64it/s]\u001B[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 282/375 [00:30<00:12,  7.58it/s]\u001B[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 283/375 [00:30<00:12,  7.49it/s]\u001B[A\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 284/375 [00:31<00:12,  7.38it/s]\u001B[A\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 285/375 [00:31<00:12,  7.11it/s]\u001B[A\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 286/375 [00:31<00:12,  7.27it/s]\u001B[A\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 287/375 [00:31<00:11,  7.36it/s]\u001B[A\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 288/375 [00:31<00:12,  7.15it/s]\u001B[A\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 289/375 [00:31<00:12,  7.09it/s]\u001B[A\n",
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 290/375 [00:31<00:11,  7.20it/s]\u001B[A\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 291/375 [00:32<00:11,  7.30it/s]\u001B[A\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 292/375 [00:32<00:12,  6.89it/s]\u001B[A\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 293/375 [00:32<00:11,  6.99it/s]\u001B[A\n",
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 294/375 [00:32<00:11,  7.08it/s]\u001B[A\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 295/375 [00:32<00:11,  7.08it/s]\u001B[A\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 296/375 [00:32<00:11,  6.75it/s]\u001B[A\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 297/375 [00:32<00:11,  6.65it/s]\u001B[A\n",
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 298/375 [00:33<00:11,  6.65it/s]\u001B[A\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 299/375 [00:33<00:11,  6.86it/s]\u001B[A\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 300/375 [00:33<00:10,  6.93it/s]\u001B[A\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 301/375 [00:33<00:10,  7.03it/s]\u001B[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 302/375 [00:33<00:10,  7.09it/s]\u001B[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 303/375 [00:33<00:10,  7.08it/s]\u001B[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 304/375 [00:33<00:09,  7.16it/s]\u001B[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 305/375 [00:34<00:09,  7.14it/s]\u001B[A\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 306/375 [00:34<00:09,  7.17it/s]\u001B[A\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 307/375 [00:34<00:09,  7.21it/s]\u001B[A\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 308/375 [00:34<00:09,  7.16it/s]\u001B[A\n",
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 309/375 [00:34<00:09,  7.13it/s]\u001B[A\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 310/375 [00:34<00:09,  7.11it/s]\u001B[A\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 311/375 [00:34<00:09,  6.97it/s]\u001B[A\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 312/375 [00:35<00:09,  6.83it/s]\u001B[A\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 313/375 [00:35<00:08,  6.99it/s]\u001B[A\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 314/375 [00:35<00:08,  6.95it/s]\u001B[A\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 315/375 [00:35<00:08,  7.05it/s]\u001B[A\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 316/375 [00:35<00:08,  7.07it/s]\u001B[A\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 317/375 [00:35<00:08,  7.04it/s]\u001B[A\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 318/375 [00:35<00:08,  6.62it/s]\u001B[A\n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 319/375 [00:36<00:08,  6.50it/s]\u001B[A\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 321/375 [00:36<00:06,  7.98it/s]\u001B[A\n",
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 323/375 [00:36<00:05,  8.91it/s]\u001B[A\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 325/375 [00:36<00:05,  9.59it/s]\u001B[A\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 327/375 [00:36<00:04, 10.02it/s]\u001B[A\n",
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 328/375 [00:36<00:04,  9.46it/s]\u001B[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 329/375 [00:37<00:05,  9.01it/s]\u001B[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 330/375 [00:37<00:05,  8.69it/s]\u001B[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 331/375 [00:37<00:05,  8.53it/s]\u001B[A\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 332/375 [00:37<00:05,  8.31it/s]\u001B[A\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 333/375 [00:37<00:05,  8.15it/s]\u001B[A\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 334/375 [00:37<00:05,  8.02it/s]\u001B[A\n",
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 335/375 [00:37<00:05,  7.97it/s]\u001B[A\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 336/375 [00:37<00:04,  7.89it/s]\u001B[A\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 337/375 [00:38<00:04,  7.91it/s]\u001B[A\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 338/375 [00:38<00:04,  7.93it/s]\u001B[A\n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 339/375 [00:38<00:04,  7.95it/s]\u001B[A\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 340/375 [00:38<00:04,  7.92it/s]\u001B[A\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 341/375 [00:38<00:04,  7.92it/s]\u001B[A\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 342/375 [00:38<00:04,  7.77it/s]\u001B[A\n",
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 343/375 [00:38<00:04,  7.82it/s]\u001B[A\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 344/375 [00:38<00:04,  7.71it/s]\u001B[A\n",
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 345/375 [00:39<00:03,  7.61it/s]\u001B[A\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 347/375 [00:39<00:03,  8.80it/s]\u001B[A\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 349/375 [00:39<00:02,  9.56it/s]\u001B[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 351/375 [00:39<00:02,  9.91it/s]\u001B[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 353/375 [00:39<00:02, 10.25it/s]\u001B[A\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 355/375 [00:40<00:01, 10.43it/s]\u001B[A\n",
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 357/375 [00:40<00:01, 10.39it/s]\u001B[A\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 359/375 [00:40<00:01, 10.60it/s]\u001B[A\n",
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 361/375 [00:40<00:01, 10.65it/s]\u001B[A\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 363/375 [00:40<00:01, 10.69it/s]\u001B[A\n",
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 365/375 [00:40<00:00, 10.69it/s]\u001B[A\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 367/375 [00:41<00:00, 10.72it/s]\u001B[A\n",
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 369/375 [00:41<00:00, 10.84it/s]\u001B[A\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 371/375 [00:41<00:00, 10.71it/s]\u001B[A\n",
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 373/375 [00:41<00:00, 10.83it/s]\u001B[A\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 375/375 [00:41<00:00,  8.95it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BLEU-1:  2.7901041666666666\n",
      "BLEU-2:  0.5171559034572734\n",
      "BLEU-3:  0.10875816993464099\n",
      "BLEU-4:  0.05448592010478028\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "bleu1, bleu2, bleu3, bleu4 = [],[],[],[]\n",
    "# Complete the testing loop\n",
    "for batch_src, batch_tgt in tqdm(test_dataloader):\n",
    "    batch_src = batch_src.to(torch.device('cuda'))\n",
    "    batch_tgt = batch_tgt.to(torch.device('cuda'))\n",
    "    with torch.no_grad():\n",
    "      output = model(batch_src)\n",
    "    pred_tokens = torch.argmax(output, dim=-1).tolist()\n",
    "    ref_tokens = batch_tgt.tolist()\n",
    "\n",
    "    reference = [[\" \".join(map(str, ref))] for ref in ref_tokens]\n",
    "    hypothese = [\" \".join(map(str, hyp)) for hyp in pred_tokens]\n",
    "\n",
    "    bleu1.append(sacrebleu.corpus_bleu(hypothese, reference).precisions[0]) # BLUE-1 gram\n",
    "    bleu2.append(sacrebleu.corpus_bleu(hypothese, reference).precisions[1]) # BLUE-2 gram\n",
    "    bleu3.append(sacrebleu.corpus_bleu(hypothese, reference).precisions[2]) # BLUE-3 gram\n",
    "    bleu4.append(sacrebleu.corpus_bleu(hypothese, reference).precisions[3]) # BLUE-4 gram\n",
    "\n",
    "print(\"BLEU-1: \", sum(bleu1) / len(bleu1))\n",
    "print(\"BLEU-2: \", sum(bleu2) / len(bleu2))\n",
    "print(\"BLEU-3: \", sum(bleu3) / len(bleu3))\n",
    "print(\"BLEU-4: \", sum(bleu4) / len(bleu4))\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sacrebleu.corpus_bleu(hypothese, reference)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PcsdJOGwueV-",
    "outputId": "d2adaf3c-2197-45ce-c45e-593338b4a847"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BLEU = 0.28 3.3/0.4/0.1/0.0 (BP = 1.000 ratio = 1.000 hyp_len = 512 ref_len = 512)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpaHAQWp7dYF"
   },
   "source": [
    "Congratulations! You can now work with RNNs for the task of Machine Translation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeBy8PO37dYF"
   },
   "source": [
    "## Q6: Prepare for training transformers (10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vauBDs_a7dYJ"
   },
   "source": [
    "In this part we cover the initial setup required before training transformer this including data preprocessing and setting up data collators and loaders.\n",
    "\n",
    "Ensure you have loaded the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AW5Y83Ew7dYK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "95abb71b-b6ed-495c-9be4-ed21ce7b024a",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:05:40.649449Z",
     "start_time": "2025-03-13T18:05:40.647624Z"
    }
   },
   "source": "print(dataset)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['translation'],\n",
      "    num_rows: 15000\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMGCBjca7dYK"
   },
   "source": [
    "We will begin by tokenizing the data. Based on your model selection load the appropriate tokenizer. We are using models from AutoModelForSeq2SeqLM in this assignment. You can checkout all the available models here: https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qr49H_Bq7dYK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e5b1ef38-cdfe-411b-f5a5-50c2e8856c54",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:08:18.530776Z",
     "start_time": "2025-03-13T18:08:17.716737Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"google-t5/t5-base\" #Select a model of your choice: MT5 model\n",
    "#checkpoint ='bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "720bd19a03d94ae69424a9ca8e7f1ae6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "702ec34fa4c947df97d128652b49a3cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b287a87a6e454e16b93a5fc548d4cfec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_FwXurd7dYK"
   },
   "source": [
    "We will need to tokenize both our input and outputs. Thus we make use of pre_process() function to generate tokenized model inputs and targets. Ensure you use truncation and padding! The max length will be 128."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KF8_JKSS7dYK",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:13:46.028125Z",
     "start_time": "2025-03-13T20:13:46.026067Z"
    }
   },
   "source": [
    "##Implement the preprocess function\n",
    "def preprocess_function(examples):\n",
    "    inputs = [example[\"fr\"] for example in examples[\"translation\"]]\n",
    "    targets = [example[\"en\"] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, padding = \"max_length\", truncation=True, max_length=128, return_tensors=\"pt\") #Instantitate tokenizer to generate model outputs\n",
    "    labels = tokenizer(targets, padding = \"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    # add tokenized target sentence to model inputs\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train_data = train_dataset.map(preprocess_function, batched=True)"
   ],
   "metadata": {
    "id": "-IwNWQEf8Fru",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:13:49.626064Z",
     "start_time": "2025-03-13T20:13:47.885608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/9600 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b84d6ae0b4c448989c0c93d59a789ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "# changed original code to eval_dataset, because val_dataset does not exist\n",
    "tokenized_eval_data = eval_dataset.map(preprocess_function, batched=True)\n"
   ],
   "metadata": {
    "id": "H42Bthkh8GHS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f97ac130c9684c31bbe4736005ce1428",
      "f7da3ede06004d2cb498672266b21410",
      "ea6182b35e584fa197014e74d1726f38",
      "ccdca5d7aafd4b698f632ad8c637c8e4",
      "ad410f7282534d6e8923f4e876834cea",
      "28c43ba6e35240b287f5ddb998f6591a",
      "504ee3f5a3064e58aa8d0efb295033de",
      "c8352910fdb64977b1b9d04ed3561b0a",
      "1193c8fb8ff040cda38d6de45f42632e",
      "e8d880c834e445a5859e5cdecf857b78",
      "6e0379aaed06452796f170e7be63d2ae"
     ]
    },
    "outputId": "a8e75ccc-5217-4893-d47b-d2409ceabe72",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:13:56.465967Z",
     "start_time": "2025-03-13T20:13:55.935540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ab1e148564442b285cd7483d75b8634"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "We remove the column 'translation' as we do not require it for training. Also often having columns other than we created using the preprocess_function may lead to errors during training. Since model might get confused which inputs it needs to use."
   ],
   "metadata": {
    "id": "R9KiU8Uw8jpI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train_data = tokenized_train_data.remove_columns(train_dataset.column_names)\n",
    "tokenized_eval_data = tokenized_eval_data.remove_columns(eval_dataset.column_names)"
   ],
   "metadata": {
    "id": "8z_WfysF8Jqz",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:13:59.308955Z",
     "start_time": "2025-03-13T20:13:59.305338Z"
    }
   },
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train_data.set_format(\"torch\")\n",
    "tokenized_eval_data.set_format(\"torch\")"
   ],
   "metadata": {
    "id": "ES0vpD308KFK",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:14:01.827338Z",
     "start_time": "2025-03-13T20:14:01.824804Z"
    }
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBKQon-E7dYK"
   },
   "source": [
    "To construct batches of training data for model training, we require collators that set the properties for the batches and data loaders that generate the batches."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8J_Bs4bT7dYK",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:08:36.489586Z",
     "start_time": "2025-03-13T18:08:36.484638Z"
    }
   },
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer) #INSTANTIATE THE COLLATOR"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2ErHyp6A7dYK",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:08:38.356355Z",
     "start_time": "2025-03-13T18:08:38.353951Z"
    }
   },
   "source": [
    "#Instantiate the DataLoader for training and evaluation data\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_train_data, batch_size=2, shuffle=True)\n",
    "eval_dataloader = DataLoader(tokenized_eval_data, batch_size=2)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq75QwZr7dYK"
   },
   "source": [
    "## Q7) Choosing & Loading the Model (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1Cr5Z0T7dYK"
   },
   "source": [
    "Choose a pre-trained transformer model that you will use for fine-tuning on the translation dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JZY0-m7L7dYK",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:12:48.089271Z",
     "start_time": "2025-03-13T18:08:51.157279Z"
    }
   },
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "checkpoint = \"google-t5/t5-base\" #\n",
    "#checkpoint = 'bert-base-multilingual-cased'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7e176cd728348d99751959257d96c56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a2f23d989f3456fa08e82e81952024b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsaL0EAC7dYK"
   },
   "source": [
    "## Q8) Training the Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKlkWxxh7dYK"
   },
   "source": [
    "Now, that we have are data tokenized and ready in batches and model fixed. We will begin with training this model. To do so we must setup the right hyperparameters, then proceed to implment the training loop to train our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1e0JWoMi7dYL"
   },
   "source": [
    "For training we require an optimizer and a scheduler to manage the learning rate during the training. Let's set them up before our training loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CxwICUp17dYL",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:13:31.420905Z",
     "start_time": "2025-03-13T18:13:31.417753Z"
    }
   },
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 2\n",
    "# for faster training speed pick below number. If time permits, use the number #num_train_epochs * len(train_dataloader)\n",
    "num_training_steps = 2000 #num_train_epochs * len(train_dataloader)\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=0.05)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": [
    "output_size = tokenizer.vocab_size\n",
    "output_size"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NC70bmJMlohf",
    "outputId": "ece7a174-f24f-42a3-8128-da79ca14e522",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:13:35.576930Z",
     "start_time": "2025-03-13T18:13:35.575001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# debug",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# debug\n",
    "num_training_steps"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "snCjMEbweegQ",
    "outputId": "f5d4f385-9a5a-49ce-d3bd-b776b96a38e4",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:14:31.190454Z",
     "start_time": "2025-03-13T18:14:31.188569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqdgWb_Q7dYL"
   },
   "source": [
    "Finally, we are here!\n",
    "\n",
    "In the loop during training you will run a forward pass, compute the loss, compute the gradients, and then update the weights. (Don't foregt to set gradient to zero!)\n",
    "\n",
    "During the eval phase we simply do a forward pass and compute the loss!"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vg0dH7osqwFw",
    "outputId": "26f6ee21-8b06-4dbb-b1e1-fbd583174cf0",
    "ExecuteTime": {
     "end_time": "2025-03-13T18:14:33.155260Z",
     "start_time": "2025-03-13T18:14:33.153070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s0iDbp0x7dYL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "b2ec212bb3f34cfd9149d39990f94ea5",
      "edd44d42f249429f8ab5accbe766c4a2",
      "df84be678d6d46fa81abb278ee93892b",
      "09edb0f2dfc44acea70d2a9118970fa5",
      "f2f176bc831a496ab3db566b4453cce6",
      "00d06a6d8f1c4ecaa152a3ced4b789dd",
      "15b33d61ffce444687e22c26d7d2bc51",
      "8f39d486ebd54faf9f697fa6f1c01732",
      "a6ab689571744d2e8e1a1202f573f53d",
      "4e1794d11bce4bd3af783fe479c94278",
      "10c1eb67ca6e4314ad55d47e7994cdd5"
     ]
    },
    "outputId": "6d74a966-0c2f-4cf9-bd81-6e6fd58de49f",
    "ExecuteTime": {
     "end_time": "2025-03-13T19:46:41.679361Z",
     "start_time": "2025-03-13T18:14:40.443691Z"
    }
   },
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "progress_bar = tqdm(total=num_training_steps, desc=\"Training Progress\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        ## Complete the training loop\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids=batch[\"input_ids\"], labels = batch[\"labels\"])\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation Phase\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "    total_eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            output = model(input_ids=batch[\"input_ids\"], labels = batch[\"labels\"])\n",
    "            loss = output.loss\n",
    "            total_eval_loss += loss.item()\n",
    "            total_batches += 1\n",
    "      ### Complete the evaluation phase\n",
    "\n",
    "    avg_loss = total_eval_loss / total_batches if total_batches > 0 else float('inf')\n",
    "    print(f\"Epoch {epoch}: Average Eval Loss: {avg_loss:.4f}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Training Progress:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9fed550d22ee485e880fac8617a653d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Average Eval Loss: 1.4497\n",
      "Epoch 1: Average Eval Loss: 1.4497\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": "The above training phase took about 90 min to run",
   "metadata": {
    "id": "Vlg_7_rNIMrU"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_7JA8gD7dYL"
   },
   "source": [
    "Congratulations!! On completing the training. Now don't forget to save your model and the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hqTmBLMG7dYL",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "outputId": "18fe657b-b58c-4cda-8933-0db7214c1786",
    "ExecuteTime": {
     "end_time": "2025-03-13T19:49:52.376808Z",
     "start_time": "2025-03-13T19:49:52.136110Z"
    }
   },
   "source": [
    "# Save model and tokenizer\n",
    "output_dir = \"HW2-transformer-model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('HW2-transformer-model/tokenizer_config.json',\n",
       " 'HW2-transformer-model/special_tokens_map.json',\n",
       " 'HW2-transformer-model/tokenizer.json')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCrwRPf-7dYL"
   },
   "source": [
    "## Q9) Evaluating Transformer for Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsteZEw77dYL"
   },
   "source": [
    "We will now test our trained model and analyze its performance using BLEU-1, 2, 3, 4 scores from the sacrebleu library. You will create a task evaluator for translation, load and process the test dataset, and compute the results on an existing trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we load a model trained for french to english translation. You can read more about it here: https://huggingface.co/Helsinki-NLP/opus-mt-tc-big-fr-en"
   ],
   "metadata": {
    "id": "YNP8tJ3Y9Yna"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T19:59:57.647836Z",
     "start_time": "2025-03-13T19:59:57.085667Z"
    }
   },
   "cell_type": "code",
   "source": "#pip install sentencepiece",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (0.2.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "checkpoint = \"Helsinki-NLP/opus-mt-tc-big-fr-en\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "metadata": {
    "id": "OUIYns7E9S2j",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:15:22.746878Z",
     "start_time": "2025-03-13T20:15:19.856500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize an evaluator for translation task"
   ],
   "metadata": {
    "id": "1HRtKCKh9mqc"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dR_Kc8NN7dYL",
    "ExecuteTime": {
     "end_time": "2025-03-13T21:10:39.842625Z",
     "start_time": "2025-03-13T21:10:39.840748Z"
    }
   },
   "source": [
    "## Load Evaluator for translation\n",
    "from evaluate import evaluator\n",
    "task_evaluator = evaluator(\"translation\")"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL8zPaFz7dYL"
   },
   "source": [
    "We will need to change our test dataset by having specific input and target columns. Thus we will use split_translation to split the translation column into two columns 'en' and 'fr'."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NMCG74Vr7dYL",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:15:39.251778Z",
     "start_time": "2025-03-13T20:15:39.249983Z"
    }
   },
   "source": [
    "#  Implement the split function\n",
    "def split_translations(example):\n",
    "    en_text = example[\"translation\"][\"en\"]\n",
    "    fr_text = example[\"translation\"][\"fr\"]\n",
    "    example['en'] = en_text\n",
    "    example['fr'] = fr_text\n",
    "    return example"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "# debug\n",
    "test_dataset"
   ],
   "metadata": {
    "id": "mQmOELHePzLj",
    "ExecuteTime": {
     "end_time": "2025-03-13T20:12:50.831139Z",
     "start_time": "2025-03-13T20:12:50.828938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NpUlKUm17dYL",
    "ExecuteTime": {
     "end_time": "2025-03-13T21:07:31.285652Z",
     "start_time": "2025-03-13T21:07:31.282451Z"
    }
   },
   "source": "test_data = test_dataset.map(split_translations)",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T21:07:39.880130Z",
     "start_time": "2025-03-13T21:07:39.878359Z"
    }
   },
   "cell_type": "code",
   "source": "print(test_data)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['translation', 'en', 'fr'],\n",
      "    num_rows: 3000\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T21:14:28.521185Z",
     "start_time": "2025-03-13T21:14:28.386253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Since I trained my model on my local mac, I could not use cuda\n",
    "# alternative is to use mps for mac\n",
    "import torch\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(53017, 1024, padding_idx=53016)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(53017, 1024, padding_idx=53016)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(1024, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(53017, 1024, padding_idx=53016)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(1024, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=53017, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA9Vt7kF7dYL"
   },
   "source": [
    "You can now go ahead and compute the results by appropriately setting up the task_evaluator.compute()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HV6gQhFP7dYL",
    "ExecuteTime": {
     "end_time": "2025-03-13T22:03:47.480295Z",
     "start_time": "2025-03-13T21:14:36.576794Z"
    }
   },
   "source": [
    "import sacrebleu\n",
    "import evaluate\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline= model,\n",
    "    data= test_data,\n",
    "    tokenizer= tokenizer,\n",
    "    metric=bleu_metric,\n",
    "    input_column=\"fr\",\n",
    "    label_column=\"en\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The above cell took 49 min to run"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AEv4BBNq7dYM",
    "ExecuteTime": {
     "end_time": "2025-03-13T22:04:08.831904Z",
     "start_time": "2025-03-13T22:04:08.830362Z"
    }
   },
   "source": [
    "print(results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 34.08882214483324, 'counts': [53693, 32107, 21160, 14448], 'totals': [81530, 78530, 75532, 72538], 'precisions': [65.85673985036183, 40.885012097287664, 28.014616321559075, 19.917836168628856], 'bp': 0.9736753990955999, 'sys_len': 81530, 'ref_len': 83705, 'total_time_in_seconds': 2144.3362929160066, 'samples_per_second': 1.3990342885632023, 'latency_in_seconds': 0.7147787643053356}\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvPJif197dYM"
   },
   "source": [
    "## Q10) Inferencing on Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2VpQtGW7dYM"
   },
   "source": [
    "Let's check out how well this trained model's translation skills are. You can use try with a few french sentence and see how well it translates.\n",
    "\n",
    "To do so we will setup a pipline using the existing trained model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6mVfvWC7dYM"
   },
   "source": [
    "Loading the tokenizer and model for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nojJlgVf7dYM",
    "ExecuteTime": {
     "end_time": "2025-03-17T00:22:55.549997Z",
     "start_time": "2025-03-17T00:22:53.743344Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "checkpoint = \"Helsinki-NLP/opus-mt-tc-big-fr-en\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53K25pUn7dYM"
   },
   "source": [
    "Setup the pipeline for translation using your model and tokenizer. You can read about pipelines here: https://huggingface.co/docs/transformers/en/main_classes/pipelines"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hKp9pNoQ7dYM",
    "ExecuteTime": {
     "end_time": "2025-03-17T00:25:57.444075Z",
     "start_time": "2025-03-17T00:25:57.272564Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "# Instatiate a pipeline for Translation using the model and tokenizer\n",
    "pipeline = pipeline(\"translation_fr_to_en\", model=model, tokenizer=tokenizer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YdV-e6sM7dYM"
   },
   "source": [
    "Translate the given sentence using the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tc8Y01YC7dYM",
    "ExecuteTime": {
     "end_time": "2025-03-17T00:28:23.532470Z",
     "start_time": "2025-03-17T00:28:23.135385Z"
    }
   },
   "source": [
    "input_text = \"J'ai mes joies, mes peines.\" # input French words/sentences\n",
    "translation_result = pipeline(input_text)"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5eRCXrNN7dYM",
    "ExecuteTime": {
     "end_time": "2025-03-17T00:28:24.936619Z",
     "start_time": "2025-03-17T00:28:24.934721Z"
    }
   },
   "source": [
    "print(translation_result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'I have my joys, my sorrows.'}]\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T00:37:25.739286Z",
     "start_time": "2025-03-17T00:37:25.737655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text1 = \"Chicago est cÂ´el`ebre pour ses pizzas profondes, son jazz et son architecï¿¾ture Â´epoustouflante.\"\n",
    "input_text2 = \"Jâ€™ai traduit cette phrase du franÂ¸cais vers lâ€™anglais.\"\n",
    "input_text3 = \"Vous avez maintenant terminÂ´e le deuxi`eme devoir de ce cours.\""
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T00:37:27.939415Z",
     "start_time": "2025-03-17T00:37:26.909035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "translate1 = pipeline(input_text1)\n",
    "translate2 = pipeline(input_text2)\n",
    "translate3 = pipeline(input_text3)"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-17T00:37:29.254044Z",
     "start_time": "2025-03-17T00:37:29.252227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(translate1)\n",
    "print(translate2)\n",
    "print(translate3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Chicago is famous for its deep pizzas, jazz and breathtaking architecture.'}]\n",
      "[{'translation_text': 'I translated this phrase from French to English.'}]\n",
      "[{'translation_text': 'You have now completed the second assignment of this course.'}]\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Note: For questions Q1-Q6, all the models were trained using Google Collab with cuda. For the rest of questions, the models were trained using Mac with MPS"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "8aecab28fc61444887162efdafc24d2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aab406e81f49463dbeb6f3336c15091a",
       "IPY_MODEL_b85d479090c0445db78fffc344f2b28a",
       "IPY_MODEL_d2275916991343fc9c3487c6f2f42f0b"
      ],
      "layout": "IPY_MODEL_8d984ce4d92b420fa6e1b82ee01cb84b"
     }
    },
    "aab406e81f49463dbeb6f3336c15091a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6554cb2c5974c918d03b531f33e9735",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_045edd3925a3497d8e121c0967ba579d",
      "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
     }
    },
    "b85d479090c0445db78fffc344f2b28a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bcd9f4e66924eb99cf5c9cf16284e53",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3445d42ac5454a0bbd2825f22cf3bf5d",
      "value": 30
     }
    },
    "d2275916991343fc9c3487c6f2f42f0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0291bb3a87d43909b64bb238f184bd1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_046061c6a2df41d5985c487bf25ec0e3",
      "value": "â€‡30/30â€‡[00:01&lt;00:00,â€‡15.23it/s]"
     }
    },
    "8d984ce4d92b420fa6e1b82ee01cb84b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6554cb2c5974c918d03b531f33e9735": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "045edd3925a3497d8e121c0967ba579d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bcd9f4e66924eb99cf5c9cf16284e53": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3445d42ac5454a0bbd2825f22cf3bf5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0291bb3a87d43909b64bb238f184bd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "046061c6a2df41d5985c487bf25ec0e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57a710bb31a14ab4a58a425f2db54e07": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ef1960222d248cf8b5e5fd5831494a3",
       "IPY_MODEL_077fbf7a2b1f4dbcbe1d803d7f64e63b",
       "IPY_MODEL_5f6f5ee76013440386dcf349c9456562"
      ],
      "layout": "IPY_MODEL_c7bb677061484f79ab7ac0403445019e"
     }
    },
    "1ef1960222d248cf8b5e5fd5831494a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f54bcd623f1e44eca44cfcdce29e7251",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a6d9eabb3ce74904919a44b9d257ac59",
      "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
     }
    },
    "077fbf7a2b1f4dbcbe1d803d7f64e63b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79375ca6f18a44c9bc13e25b3cec9c07",
      "max": 30,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3e2a614fc02e4029a38051f7e09854ae",
      "value": 30
     }
    },
    "5f6f5ee76013440386dcf349c9456562": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acfaf67f57dc4c90bd0bc5c4a8e9d629",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0b36c2cc6ed840c08aa615d2ae496070",
      "value": "â€‡30/30â€‡[00:00&lt;00:00,â€‡44.51it/s]"
     }
    },
    "c7bb677061484f79ab7ac0403445019e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f54bcd623f1e44eca44cfcdce29e7251": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6d9eabb3ce74904919a44b9d257ac59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79375ca6f18a44c9bc13e25b3cec9c07": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e2a614fc02e4029a38051f7e09854ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "acfaf67f57dc4c90bd0bc5c4a8e9d629": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b36c2cc6ed840c08aa615d2ae496070": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f97ac130c9684c31bbe4736005ce1428": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7da3ede06004d2cb498672266b21410",
       "IPY_MODEL_ea6182b35e584fa197014e74d1726f38",
       "IPY_MODEL_ccdca5d7aafd4b698f632ad8c637c8e4"
      ],
      "layout": "IPY_MODEL_ad410f7282534d6e8923f4e876834cea"
     }
    },
    "f7da3ede06004d2cb498672266b21410": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28c43ba6e35240b287f5ddb998f6591a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_504ee3f5a3064e58aa8d0efb295033de",
      "value": "Map:â€‡100%"
     }
    },
    "ea6182b35e584fa197014e74d1726f38": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8352910fdb64977b1b9d04ed3561b0a",
      "max": 2400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1193c8fb8ff040cda38d6de45f42632e",
      "value": 2400
     }
    },
    "ccdca5d7aafd4b698f632ad8c637c8e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8d880c834e445a5859e5cdecf857b78",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6e0379aaed06452796f170e7be63d2ae",
      "value": "â€‡2400/2400â€‡[00:02&lt;00:00,â€‡972.97â€‡examples/s]"
     }
    },
    "ad410f7282534d6e8923f4e876834cea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28c43ba6e35240b287f5ddb998f6591a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "504ee3f5a3064e58aa8d0efb295033de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8352910fdb64977b1b9d04ed3561b0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1193c8fb8ff040cda38d6de45f42632e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8d880c834e445a5859e5cdecf857b78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e0379aaed06452796f170e7be63d2ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2ec212bb3f34cfd9149d39990f94ea5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_edd44d42f249429f8ab5accbe766c4a2",
       "IPY_MODEL_df84be678d6d46fa81abb278ee93892b",
       "IPY_MODEL_09edb0f2dfc44acea70d2a9118970fa5"
      ],
      "layout": "IPY_MODEL_f2f176bc831a496ab3db566b4453cce6"
     }
    },
    "edd44d42f249429f8ab5accbe766c4a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00d06a6d8f1c4ecaa152a3ced4b789dd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_15b33d61ffce444687e22c26d7d2bc51",
      "value": "Trainingâ€‡Progress:â€‡"
     }
    },
    "df84be678d6d46fa81abb278ee93892b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f39d486ebd54faf9f697fa6f1c01732",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6ab689571744d2e8e1a1202f573f53d",
      "value": 2000
     }
    },
    "09edb0f2dfc44acea70d2a9118970fa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e1794d11bce4bd3af783fe479c94278",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_10c1eb67ca6e4314ad55d47e7994cdd5",
      "value": "â€‡4095/?â€‡[29:50&lt;00:00,â€‡â€‡2.30it/s]"
     }
    },
    "f2f176bc831a496ab3db566b4453cce6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "00d06a6d8f1c4ecaa152a3ced4b789dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15b33d61ffce444687e22c26d7d2bc51": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f39d486ebd54faf9f697fa6f1c01732": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6ab689571744d2e8e1a1202f573f53d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e1794d11bce4bd3af783fe479c94278": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10c1eb67ca6e4314ad55d47e7994cdd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
